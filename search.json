[{"path":"/2024/10/12/follow/","content":"This message is used to verify that this feed (feedId:58340484760415232) belongs to me (userId:67521871361650688). Join me in enjoying the next generation information browser https://follow.is."},{"title":"Proxmox VE 云桌面实战 ④ - 打造属于自己的Linux云电脑 - Ubuntu篇","path":"/2023/07/21/pve-cloud-desktop-hands-on-4/","content":"前言接上文，本文将讲述如何在Ubuntu 22.04.2 LTS上配置Sunshine云桌面环境 安装Ubuntu虚拟机配置同上文，为了方便安装NVIDIA驱动，同样不启用安全启动 这里选择最简单的ext4分区： 截屏2023-07-21 09.17.20 配置用户时，勾选自动登录，原因详见上文： 截屏2023-07-21 09.18.49 安装GRID驱动确保系统最新12sudo apt updatesudo apt upgrade 如果升级了内核，则需重启 1reboot 安装依赖1sudo apt install linux-headers-$(uname -r) gcc make dkms libglvnd-core-dev libglvnd0 libglvnd-dev 禁用nouveau驱动1echo &quot;blacklist nouveau&quot; &gt;&gt; /etc/modprobe.d/blacklist-nouveau.conf 更新initramfs1sudo update-initramfs -u -k all 重启到多用户模式12sudo systemctl set-default multi-user.targetreboot 安装GRID驱动123sudo -ichmod +x ./NVIDIA-Linux-x86_64-535.54.03-grid.run./NVIDIA-Linux-x86_64-535.54.03-grid.run 截屏2023-07-21 09.52.42 弹出建议使用软件源安装的提示，选择继续安装 截屏2023-07-20 16.33.03 安装32位兼容库 截屏2023-07-20 16.34.12 注册为DKMS模块，这样内核更新后驱动会重新编译以自动适配新内核 截屏2023-07-20 16.36.00 我们需要手动生成X配置文件，选择No 重启到图形模式12sudo systemctl set-default graphical.targetreboot 激活vGPU许可12sudo curl --insecure -X GET https://&lt;fastapi-dls-ip&gt;/client-token -o /etc/nvidia/ClientConfigToken/client_configuration_token.toksudo systemctl restart nvidia-gridd 可以执行以下命令查看是否生效： 123rickg@clouddesktop:~$ nvidia-smi -q | grep &quot;License&quot; vGPU Software Licensed Product License Status : Licensed (Expiry: 2028-7-19 2:7:2 GMT) 安装Sunshine下载&amp;安装前往GitHub Release页面下载Sunshine https://github.com/LizardByte/Sunshine/releases/https://github.com/LizardByte/Sunshine/releases/ 1sudo apt install ./sunshine-ubuntu-22.04-amd64.deb 添加udev规则Sunshine需要uinput的权限才能创建鼠标和虚拟手柄事件 12echo &#x27;KERNEL==&quot;uinput&quot;, SUBSYSTEM==&quot;misc&quot;, OPTIONS+=&quot;static_node=uinput&quot;, TAG+=&quot;uaccess&quot;&#x27; | \\sudo tee /etc/udev/rules.d/85-sunshine.rules 随后重启 1reboot 配置GDM &amp; XorgGDM编辑/etc/gdm3/custom.conf，去除WaylandEnable=false的注释： 1234567891011121314151617181920212223242526272829# GDM configuration storage## See /usr/share/gdm/gdm.schemas for a list of available options.[daemon]AutomaticLoginEnable=trueAutomaticLogin=rickg# Uncomment the line below to force the login screen to use XorgWaylandEnable=false# Enabling automatic login# Enabling timed login# TimedLoginEnable = true# TimedLogin = user1# TimedLoginDelay = 10[security][xdmcp][chooser][debug]# Uncomment the line below to turn on debugging# More verbose logs# Additionally lets the X server dump core if it crashes#Enable=true Xorg编辑/etc/X11/xorg.conf： 1234567891011121314151617181920212223242526Section &quot;ServerLayout&quot; Identifier &quot;Layout0&quot; Screen 0 &quot;Screen0&quot;EndSectionSection &quot;Monitor&quot; Identifier &quot;Monitor0&quot;EndSectionSection &quot;Device&quot; Identifier &quot;Device0&quot; Driver &quot;nvidia&quot; VendorName &quot;NVIDIA Corporation&quot; BoardName &quot;GRID P40-8Q&quot; BusID &quot;PCI:1:0:0&quot;EndSectionSection &quot;Screen&quot; Identifier &quot;Screen0&quot; Device &quot;Device0&quot; Monitor &quot;Monitor0&quot; DefaultDepth 24 SubSection &quot;Display&quot; Depth 24 EndSubSectionEndSection BoardName即GPU型号，BusID根据实际情况来，执行lspci | grep VGA： 123rickg@clouddesktop:~$ lspci | grep VGA00:01.0 VGA compatible controller: Device 1234:1111 (rev 02)01:00.0 VGA compatible controller: NVIDIA Corporation GP102GL [Tesla P40] (rev a1) 可以看到vGPU的ID是01:00.0，BusID则为”PCI:1:0:0” 连接到VM重启VM，ssh连接到VM，启动Sunshine服务： 1systemctl enable --now --user sunshine 访问https://&lt;vm-ip&gt;:47990/，进入WebUI 截屏2023-07-20 17.20.36 首次配置用户名密码 截屏2023-07-21 10.28.12 可以看到启用了NVENC硬件编码和NVFBC捕获 打开Moonlight，连接，配对，云桌面就在眼前： 截屏2023-07-21 10.32.11 参考资料Install NVIDIA Drivers on Debian &#x2F; Ubuntu &#x2F; Linux Mint &#x2F; LMDE :: If Not True Then False (if-not-true-then-false.com) Sunshine documentation (lizardbyte.dev)","tags":["云桌面","PVE","Linux"]},{"title":"Proxmox VE 云桌面实战 ③ - 打造属于自己的Linux云电脑 - Fedora篇","path":"/2023/07/20/pve-cloud-desktop-hands-on-3/","content":"前言这是云桌面的第三篇，Windows云电脑大家听过很多，可你有曾想过，Linux搭配Desktop Environment也能打造云电脑，本文将介绍如何在Fedora 38上使用Sunshine搭建云桌面服务。 虚拟机配置虚拟机配置如下，hostpci0为P40 vGPU，mDev型号为GRID-P40-8Q，hostpci1为82599 SR-IOV网卡，由于需要安装NVIDIA驱动，创建EFI磁盘时不勾选预注册密钥一项。 截屏2023-07-20 15.06.23 安装Fedora从ISO启动，因为这是虚拟镜像，选择Install Fedora 38 截屏2023-07-20 15.13.56 选择语言后继续，配置安装源，如图所示，这里使用清华源 截屏2023-07-20 15.17.09 选择软件，这里我选择Fedora Workstation，如果喜欢别的DE也可以选择其他的 截屏2023-07-20 15.18.34 进行分区，这里使用Btrfs分区 添加一个300M分区，挂载点/boot/efi 截屏2023-07-20 15.22.37 添加Swap（可选） 添加Btrfs卷，大小为剩下的所有，名称为@，如图所示 截屏2023-07-20 15.25.58 在数据中添加/home挂载点，名称为@home，如图所示 截屏2023-07-20 15.27.41 随后开始安装，喝杯☕️吧！ 安装NVIDIA GRID驱动提示本文所用驱动为GRID 16.0，版本为535.54.03 确保系统最新1sudo dnf update 如果升级了内核，需要重启 1reboot 安装依赖1sudo dnf install kernel-devel kernel-headers gcc make dkms acpid libglvnd-glx libglvnd-opengl libglvnd-devel pkgconfig 禁用nouveaunouveau是开源nvidia驱动，它与grid驱动冲突，必须禁用它 编辑/etc/modprobe.d/blacklist-nouveau.conf： 1blacklist nouveau 编辑/etc/default/grub： 在GRUB_CMDLINE_LINUX=”…”中添加rd.driver.blacklist=nouveau和nvidia-drm.modeset=1，如下所示： 1GRUB_CMDLINE_LINUX=&quot;rhgb quiet rd.driver.blacklist=nouveau nvidia-drm.modeset=1&quot; 更新grub配置： 1sudo grub2-mkconfig -o /boot/grub2/grub.cfg 删除nouveau驱动： 1sudo dnf remove xorg-x11-drv-nouveau 备份旧initramfs： 1sudo mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r)-nouveau.img 生成initramfs： 1sudo dracut /boot/initramfs-$(uname -r).img $(uname -r) 重启到多用户模式12sudo systemctl set-default multi-user.targetreboot 安装驱动123sudo -ichmod +x ./NVIDIA-Linux-x86_64-535.54.03-grid.run./NVIDIA-Linux-x86_64-535.54.03-grid.run 截屏2023-07-20 16.33.03 安装32位兼容库 截屏2023-07-20 16.34.12 注册为DKMS模块，这样内核更新后驱动会重新编译以自动适配新内核 截屏2023-07-20 16.36.00 我们需要手动生成X配置文件，选择No 重启到图形模式12sudo systemctl set-default graphical.targetreboot 激活vGPU许可12sudo curl --insecure -X GET https://&lt;fastapi-dls-ip&gt;/client-token -o /etc/nvidia/ClientConfigToken/client_configuration_token.toksudo systemctl restart nvidia-gridd 可以执行以下命令查看是否生效： 123[rickg@clouddesktop ~]$ nvidia-smi -q | grep &quot;License&quot; vGPU Software Licensed Product License Status : Licensed (Expiry: 2028-7-18 9:24:33 GMT) 安装Sunshine添加rpmfusion12sudo dnf install https://mirrors.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\https://mirrors.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm 安装Sunshine前往GitHub Release页面下载Sunshine https://github.com/LizardByte/Sunshine/releases/https://github.com/LizardByte/Sunshine/releases/ 1sudo dnf install ./sunshine-fedora-38-amd64.rpm 添加udev规则Sunshine需要uinput的权限才能创建鼠标和虚拟手柄事件 12echo &#x27;KERNEL==&quot;uinput&quot;, SUBSYSTEM==&quot;misc&quot;, OPTIONS+=&quot;static_node=uinput&quot;, TAG+=&quot;uaccess&quot;&#x27; | \\sudo tee /etc/udev/rules.d/85-sunshine.rules 随后重启 1reboot 配置GDM由于X的权限问题，以用户身份运行的Sunshine无法访问GDM登录界面，因此需要配置GDM自动登录。 12[root@clouddesktop ~]$ xrandr --display :0Authorization required, but no authorization protocol specified. Can&#x27;t open display :0 禁用Wayland笔者需要自定义X配置文件，而GDM默认在Wayland上运行，因此需要禁用Wayland，使GDM在Xorg上运行。 编辑/etc/gdm/custom.conf，去除WaylandEnable=false的注释： 123456789101112131415# GDM configuration storage[daemon]# Uncomment the line below to force the login screen to use XorgWaylandEnable=false[security][xdmcp][chooser][debug]# Uncomment the line below to turn on debugging#Enable=true 配置自动登录在[daemon]下添加AutomaticLoginEnable=true和AutomaticLogin=user，其中user为用户名： 1234567891011121314151617# GDM configuration storage[daemon]# Uncomment the line below to force the login screen to use XorgWaylandEnable=falseAutomaticLoginEnable=trueAutomaticLogin=rickg[security][xdmcp][chooser][debug]# Uncomment the line below to turn on debugging#Enable=true 配置Xorg编辑/etc/X11/xorg.conf： 1234567891011121314151617181920212223242526Section &quot;ServerLayout&quot; Identifier &quot;Layout0&quot; Screen 0 &quot;Screen0&quot;EndSectionSection &quot;Monitor&quot; Identifier &quot;Monitor0&quot;EndSectionSection &quot;Device&quot; Identifier &quot;Device0&quot; Driver &quot;nvidia&quot; VendorName &quot;NVIDIA Corporation&quot; BoardName &quot;GRID P40-8Q&quot; BusID &quot;PCI:1:0:0&quot;EndSectionSection &quot;Screen&quot; Identifier &quot;Screen0&quot; Device &quot;Device0&quot; Monitor &quot;Monitor0&quot; DefaultDepth 24 SubSection &quot;Display&quot; Depth 24 EndSubSectionEndSection BoardName即GPU型号，BusID根据实际情况来，执行lspci | grep VGA： 123[rickg@clouddesktop ~]$ lspci | grep VGA00:01.0 VGA compatible controller: Device 1234:1111 (rev 02)01:00.0 VGA compatible controller: NVIDIA Corporation GP102GL [Tesla P40] (rev a1) 可以看到vGPU的ID是01:00.0，BusID则为”PCI:1:0:0” 连接到VM重启VM，可以看到PVE VNC端画面定在了开机画面的最后，这是因为输出已经指向vGPU内建的虚拟显示器 SSH连接到VM，启动Sunshine服务 1systemctl enable --now --user sunshine 访问https://&lt;vm-ip&gt;:47990/，进入WebUI 截屏2023-07-20 17.20.36 首次配置用户名密码 截屏2023-07-20 17.49.20 可以看到启用了NVENC硬件编码 打开Moonlight，连接，配对，云桌面就在眼前： 截屏2023-07-20 18.00.43 可以看到GPU是在工作的： 截屏2023-07-20 18.02.59 如果网络环境好的话，云桌面体验下来还是非常流畅的 参考资料Fedora 38&#x2F;37&#x2F;36 NVIDIA Drivers Install Guide :: If Not True Then False (if-not-true-then-false.com) GDM - ArchWiki (archlinux.org) Sunshine documentation (lizardbyte.dev)","tags":["云桌面","PVE","Linux"]},{"title":"Proxmox VE 云桌面实战 ② - Windows篇","path":"/2023/07/20/pve-cloud-desktop-hands-on-2/","content":"前言上文笔者配置好了vGPU相关，那么本文笔者将创建一个简单的Windows云桌面。 方案对于云桌面，不谈那些高大上的企业级方案，毕竟搞到了也没有授权（ 既然说“简单”，那来讲讲以下几个简单的方案吧： SPICE VNC Parsec Moonlight + Sunshine SPICE可以说是最快捷的方案了，直接被Proxmox VE所集成，甚至VM在安装QXL驱动之后还能拥有简单的3D功能（前提要Windows 8.1以上 缺点也很明显，有点卡，只支持Windows、Linux、Mac（Mac甚至要自己编译 QXL羸弱的图形性能，跑3D应用是别想了 PVE里面有个SPICE增强，里面可以开启Video Streaming，个人认为也就是所谓的串流，但感觉开启了也没什么效果。 不过对于轻度使用和没有vGPU的情况，SPICE倒是不错的方案（毕竟不需要在VM上装VNC Server什么的，并且支持剪贴板共享 VNCVNC（Virtual Network Computing）是一种图形桌面共享系统，使用RFB（远程帧缓冲）协议来提供远程控制功能。在云桌面应用中，VNC可以用来实现对远程虚拟机的访问和管理。 VNC的优点在于跨平台，其客户端非常之多，安全性也较高，同时也支持剪贴板共享 缺点在于，貌似也不支持GPU加速（如有知道的大佬请在评论区指正 串流最棒的方案，但是对于网络和硬件要求也最苛刻 你需要有一块支持编解码的GPU，以及较高的网络上行带宽 https://www.bilibili.com/read/cv11681088https://www.bilibili.com/read/cv11681088 这里介绍两种：Parsec、Moonlight Parsec是付费软件，但有免费版本，只不过少了无头显示，4:4:4颜色模式等功能。 Moonlight则完全免费、开源，配合Sunshine使用可以实现4K HDR云游戏（如果条件符合的话） 对于网络，Parsec支持P2P连接 &amp; IPv6，而Moonlight + Sunshine需要手动配置端口转发（不支持IPv6） 虚拟机配置截屏2023-07-19 08.58.23 包含一块NVIDIA vGPU，mDev类型为nvidia-52，对于vGPU类型，见上一篇文章 截屏2023-07-19 08.52.34 配置SPICESPICE基本不需要配置，只需要安装spice-guest-tools即可 下载spice-guest-tools https://www.spice-space.org/download/windows/spice-guest-tools/spice-guest-tools-latest.exehttps://www.spice-space.org/download/windows/spice-guest-tools/spice-guest-tools-latest.exe 截屏2023-07-19 09.06.04 同意许可协议 截屏2023-07-19 09.06.38 同意安装驱动 截屏2023-07-19 09.07.27 安装完成 登录Proxmox VE，点击VM，点击控制台，下载pve-spice.vv文件 截屏2023-07-19 09.10.43 下载virt-viewer并安装 https://releases.pagure.org/virt-viewer/virt-viewer-x64-11.0-1.0.msihttps://releases.pagure.org/virt-viewer/virt-viewer-x64-11.0-1.0.msi 对于Linux，执行以下命令 1234# Fedorasudo dnf install virt-manager# Ubuntu &amp; Debiansudo apt install virt-manager 打开pve-spice.vv，可以看到VM画面并控制VM 截屏2023-07-19 09.18.18 配置VNC下载任意VNC Server软件，这里我使用TightVNC https://www.tightvnc.com/download.phphttps://www.tightvnc.com/download.php 截屏2023-07-19 09.23.28 同意许可协议 安装方式选择“Custom”，勾选TightVNC Server 截屏2023-07-19 09.24.10 将TightVNC Server注册为系统服务 截屏2023-07-19 09.24.54 安装完成后，会提示是否设置VNC密码，这里设置一个 打开VNC Viewer，这里我使用的是RealVNC Viewer https://www.realvnc.com/en/connect/download/viewer/https://www.realvnc.com/en/connect/download/viewer/ 输入VM的IP，回车连接 截屏2023-07-19 09.40.19 提示连接未加密，点击“Continue”继续 截屏2023-07-19 09.40.48 输入密码，点击OK连接 截屏2023-07-19 09.42.44 由于VNC服务器的限制，会话没有声音，如果有需求，建议使用RealVNC Server或者SPICE。 配置Parsec安装前往Parsec官网下载Parsec https://parsec.app/https://parsec.app/ 截屏2023-07-20 08.56.04 平台 作为主机 作为客户端 Windows ✅ ✅ Linux ✅ Mac ✅ ✅ Android ✅ 安装时务必选择Shared方式安装，这样Parsec会以系统用户权限运行，开机时就自动服务，可以显示登录画面而后手动登录。 截屏2023-07-20 09.05.50 安装完成后弹出登录界面 截屏2023-07-20 09.07.30 Parsec需要联网登录使用，如果是内网环境是使用不了Parsec的 没有账户的，直接点击Sign up注册即可 系统要求客户端没有硬性要求硬件解码，但若要有良好体验，则Intel QSV &#x2F; AMD AMF &#x2F; NVENC是必须的 对于网络，有IPv6为最好 服务端服务端要求较为严苛，硬件编解码为必须（即类似NVENC &#x2F; NVDEC），若没有则会在连接时提示主机不支持硬件编解码 截屏2023-07-20 09.14.17 对于网络，有IPv6为最好，在无IPv6情况下，全锥NAT &gt; 限制NAT &gt; 对称NAT 对称型NAT可能导致无法连接 具体可以参见佛西大佬的教程 配置vGPU授权由于目前vGPU没有授权，所以是不能编解码的，这是就要用上之前配置好的fastapi-dls项目了 打开https://&lt;fastapi-dis-ip&gt;/，可以看到fastapi-dls的介绍页面 截屏2023-07-20 09.23.04 往下翻，找到这一部分，这就是官方的配置教程： 截屏2023-07-20 09.24.00 下载https://&lt;fastapi-dls-ip&gt;/client-token，保存到C:\\Program Files\\NVIDIA Corporation\\vGPU Licensing\\ClientConfigToken目录，而后重启VM或重启NVContainerLocalSystem服务，可以看到获得了vGPU授权： 截屏2023-07-20 09.30.29 参数配置服务端 参数 解释 Hosting Enabled 是否运行为服务端 Host Name 主机名，请通过Windows设置修改 Resolution 分辨率 Bandwidth 码率限制 FPS 帧率，一般选60 Exclusive Input Mode 鼠标独占模式 Display 使用的显示器，免费版只能选一个 Audio 使用的声卡 Echo cancelling 回声消除 Virtual Gamepad Type 虚拟手柄类型，有Xbox 360、PS4、PS5三种 Quality 质量，有低延迟、平衡、高质量三种 Idle Kick Timer 挂机自动踢出 客户端配置的项目不多，连上服务端后，有以下几个选项 截屏2023-07-20 09.38.21 参数 解释 Hide Button 隐藏Parsec按钮 Chat 聊天，用于多人控制一台服务端时 Windowed 窗口模式 Sound On 打开声音 Codec 编码器 Decoder 解码器 Prefer 4:4:4 Color 优先4:4:4（需要付费） Resolution 分辨率 Bandwidth Limit 码率限制 Constant FPS 恒定FPS Send CTRL+ALT+DEL 发送CTRL+ALT+DEL -800错误解决办法有时打开Parsec会提示-800错误，无法连接到服务器，此情况一般是登录服务器被运营商屏蔽或是受到其他影响，需要为Parsec配置代理。 打开Parsec，点击Settings，一直往底下拉，找到edit the configuration file directly 截屏2023-07-20 09.48.34 随后打开配置文件，在配置文件中加入以下内容： 1234app_proxy_address = 127.0.0.1app_proxy_scheme = httpapp_proxy = trueapp_proxy_port = 7890 其中7890（端口）和http（代理类型）根据你本地运行的代理软件而定。 配置Sunshine介绍Sunshine是一个为Moonlight设计的云游戏服务端，它提供低延迟的云游戏能力，支持用AMD、Intel和Nvidia的GPU进行硬件编码，同时也支持软件编码。您可以从任何设备的Moonlight客户端连接到Sunshine，Sunshine提供了一个网页用户界面，用户可以从浏览器进行配置和客户端配对。可以从本地服务器或任何移动设备进行配对。 官方配置要求官方提示该配置要求仅供参考，请勿按照此表格购买相关硬件 最低配置 类型 要求 GPU AMD：VCE 1.0或更高，参见obs-amd hardware support Intel：兼容,VA-API，参见VAAPI hardware support Nvidia：支持NVENC的GPU，参见nvenc support matrix CPU AMD: Ryzen 3 或更高 Intel: Core i3 或更高 RAM 4GB + OS Windows: 10 +（不支持Windows Server） macOS: 11.7 + Linux&#x2F;Debian: 11 (bullseye) Linux&#x2F;Fedora: 36 + Linux&#x2F;Ubuntu: 20.04 + (focal) 网络 服务端：5GHz, 802.11ac 客户端：5GHz, 802.11ac 4K推荐配置 类型 要求 GPU AMD: Video Coding Engine 3.1 + Intel: HD Graphics 510 + Nvidia: GeForce GTX 1080 + CPU AMD: Ryzen 5 + Intel: Core i5 + 网络 Host: CAT5e ethernet or better Client: CAT5e ethernet or better 安装前往Sunshine的Release页面下载 https://github.com/LizardByte/Sunshine/releaseshttps://github.com/LizardByte/Sunshine/releases Windows平台下载sunshine-windows-installer.exe即可 截屏2023-07-20 12.44.14 选择组件时，注意勾选Launch on Startup（开机自启动）和Add Firewall Exclude（添加防火墙例外） 配置安装完成后，访问https://localhost:47990/进入Sunchine配置界面，首次配置需要设置用户名和密码 首先打开Troubleshooting，在Logs处往下拉，若找到Found encoder nvenc: [h264_nvenc, hevc_nvenc]，则表明GPU编码工作正常，否则将使用软件编码 截屏2023-07-20 13.23.09 General页该页面主要配置一些通用选项 名称 解释 Sunshine Name 主机名，显示在Moonlight连接页面中，若不填为计算机名 Log Level 日志等级，默认为Info Logfile Path 日志文件目录，默认为sunshine.log Origin Web UI Allowed 允许哪些网络上的计算机访问WebUI，默认为局域网 UPnP 通用即插即用（端口转发），默认为关 Gamepads 虚拟游戏手柄，有Xbox 360和PS4，默认为Xbox 360 Ping Timeout Ping 超时，超出此时间则断开连接 Advertised Resolutions and FPS Sunshine向客户端发送的建议的分辨率，一些客户端（如Switch客户端）需要此分辨率来确定请求的分辨率是否被支持。不影响实际推流的分辨率。 Map Right Alt key to Windows key 将右Alt键映射到Win键，当按Win键没反应时可以使用 Command Preparations 配置一个命令列表，这些命令将在运行任何应用程序之前或之后执行。如果任何指定的预备命令失败，应用程序的启动过程将被终止。 Files页该页面主要配置HTTPS证书和配置文件的目录 名称 解释 Private Key HTTPS私钥，必须为2048 bits Cert HTTPS证书，必须签名为一个2048 bits密钥 State File 存储Sunshine当前状态的文件 Apps File 存储Sunshine Apps的文件 Input页该页面主要配置输入相关 名称 解释 Home&#x2F;Guide Button Emulation Timeout 游戏手柄Home键模拟超时。如果按住Back&#x2F;Select按钮的时间达到指定的毫秒数，将会模拟按下Home&#x2F;Guide按钮。如果设置为小于0的值（默认情况下），按住返回&#x2F;选择按钮不会模拟按下Home&#x2F;Guide按钮。 Enable Mouse Input 启用鼠标输入 Enable Keyboard Input 启用键盘输入 Enable Gamepad Input 启用手柄输入 Key Repeat Delay 按键重复延迟，单位毫秒 Key Repeat Frequency 按键重复频率，即每秒一个键最多按几次 Audio &#x2F; Video页该页主要配置音视频相关 名称 解释 Audio Sink 音频源，建议留空以便自动检测。运行安装目录下的tools\\audio-info.exe获取声卡名称。 Virtual Sink 虚拟音频源，建议留空以便自动检测 Install Steam Audio Drivers 安装Steam音频驱动，如果Steam在服务器上安装，这会自动安装驱动以支持5.1&#x2F;7.1环绕声并将原有声卡静音 Adapter Name 用于捕获的显卡名称，建议留空以便自动检测，该显卡必须连接到显示器且通电。运行安装目录下的tools\\dxgi-info.exe获取显卡名称 Output Name 连接到该显卡的显示器名称，若留空则使用主显示器，一般配合Adapter Name使用 DwmFlush 提升鼠标移动时的捕获平滑度。若遇到和垂直同步相关问题请禁用 Advanced页该页主要配置高级选项 名称 解释 Port Sunshine服务使用的端口，留空为47989。关于端口转发相关请往下看 Quantization Parameter 量化参数，在不支持CBR（恒定比特率）的设备上使用，更高表示更大的压缩、更差的质量 Minimum Software Encoding Thread Count 最小软件编码线程数。稍微增加该值会降低编码效率，但通常为了能够使用更多的CPU核心进行编码，这种权衡是值得的。理想的值是能在您的硬件上可靠地按照您期望的流媒体设置进行编码的最低值。 HEVC Support HEVC支持。对于软件编码服务端请谨慎考虑。 Force a Specific Encoder 强制指定编码器，不建议使用 FEC Percentage 每个视频帧中每个数据包的纠错包的百分比。更高的值可以纠正更多的丢包，但代价是增加带宽使用。默认值20是GeForce Experience所使用的值。 Channels 频道，一般用于以下场景：1.多个客户端分别从LAN和WAN连接，需要不同的码率。2.解码器需要不同的颜色配置。 Web Manager Credentials File Web UI凭据文件，保存用户名和密码（ Origin PIN Allowed 要求PIN配对的来源，默认为localhost不需要PIN配对 External IP 监听的外部IP，留空为自动检测 配置端口转发在路由器 &#x2F; FRP上转发以下端口 端口 类型 47984 TCP 47989 TCP 47998 UDP 47999 UDP 48000 UDP 48002 UDP 48010 TCP &#x2F; UDP 连接到Sunshine前往Moonlight Github Release页面下载Moonlight客户端 https://github.com/moonlight-stream/moonlight-qt/releaseshttps://github.com/moonlight-stream/moonlight-qt/releases 安装完成后打开，点击右上角的手动添加计算机，输入IP 截屏2023-07-20 13.59.16 添加后出现计算机，但是现在有锁，需要进行PIN验证，点击计算机图标，弹出对话框 截屏2023-07-20 14.01.15 随后在Sunshine控制面板的PIN页面中输入PIN，建立连接 截屏2023-07-20 14.04.02 点击Desktop，稍等片刻，云桌面就出现在我们眼前了。 截屏2023-07-20 14.06.28 参考资料SPICE - Proxmox VE Home (spice-space.org) Virtual Network Computing - Wikipedia Moonlight Game Streaming: Play Your PC Games Remotely (moonlight-stream.org) LizardByte&#x2F;Sunshine: Self-hosted game stream host for Moonlight. (github.com) Connect to Work or Games from Anywhere | Parsec 佛西博客 - 人人走向云游戏——Parsec详解 (buduanwang.vip)","tags":["云桌面","PVE","Windows"]},{"title":"Proxmox VE 云桌面实战 ① - 配置NVIDIA vGPU","path":"/2023/07/17/pve-cloud-desktop-hands-on-1/","content":"前言随着互联网设施的建设和云计算的发展，“云桌面”、“云游戏”等概念已逐渐走入人们的视线。无论如何，它都改变了我们理解硬件性能和游戏体验的方式。本系列文章将介绍如何使用Proxmox VE构建一个简单的，支持Windows、Linux的云桌面系统。 认识vGPU要为VM添加图形功能，一般有三种方法： 软件模拟（如“标准VGA”，“VMware SVGA II”） PCI Passthrough vGPU（mDev &#x2F; sr-IOV） 性能为 PCI Passthrough &gt; vGPU &gt; 软件模拟 对于vGPU，市面上有三种方案： Intel AMD NVIDIA GVT-g MxGPU NVIDIA vGPU 笔者采用的是NVIDIA Tesla P40这款GPU，故本文只介绍NVIDIA vGPU。 vGPU架构 从上图可以看出，NVIDIA vGPU的实现由软硬件协同而成，硬件上有GPU，软件上有NVIDIA vGPU Manager。 vGPU支持的显卡一般情况下，vGPU只支持数据中心级的Tesla GPU和部分Quadro GPU，大致如下： 架构 型号 Maxwell M6, M10, M60 Pascal P4, P6, P40, P100, P100 12GB Volta V100 Turing T4, RTX 6000, RTX 6000 passive, RTX 8000, RTX 8000 passive Ampere A2, A10, A16, A40, RTX A5000, RTX A5500, RTX A6000 Ada L4, L40, RTX 6000 Ada 不过有热心大神开发了解锁补丁，可以在9，10，20系显卡上解锁vGPU功能，具体链接及教程如下： https://github.com/mbilker/vgpu_unlock-rshttps://github.com/mbilker/vgpu_unlock-rs https://gitlab.com/polloloco/vgpu-proxmoxhttps://gitlab.com/polloloco/vgpu-proxmox 支持的平台根据官方文档，目前支持的平台如下： Citrix XenServer Linux with KVM（比如Proxmox VE） Microsoft Azure Stack HCI Microsoft Windows Server（即Hyper-V） Nutanix AHV VMware vSphere ESXi vGPU类型NVIDIA官方介绍如下： vCS：NVIDIA 虚拟计算服务器，加速基于 KVM 的基础架构上的虚拟化 AI 计算工作负载。（如GRID P40-1C） vWS： NVIDIA RTX 虚拟工作站，适用于使用图形应用程序的创意和技术专业人士的虚拟工作站。（如GRID P40-1Q） vPC： NVIDIA 虚拟 PC，适用于使用办公效率应用程序和多媒体的知识工作者的虚拟桌面 (VDI)。（如GRID P40-1B） vApp： NVIDIA 虚拟应用程序，采用远程桌面会话主机 (RDSH) 解决方案的应用程序流。（如GRID P40-1A） 准备vGPU驱动注意本文中使用的Proxmox VE版本为8.0.3，内核版本为6.2.16-4-pve 移除企业源Proxmox VE默认使用企业源，如果没有订阅密钥是没有权限访问的 12echo &quot;deb https://mirrors.tuna.tsinghua.edu.cn/proxmox/debian bookworm pve-no-subscription&quot; &gt;&gt; /etc/apt/sources.list.d/pve-no-subscription.listrm /etc/apt/sources.list.d/pve-enterprise.list 更新系统123apt updateapt dist-upgradereboot 保证内核为最新版本 安装必要工具1apt install -y git build-essential dkms pve-headers mdevctl 其中dkms保证在每次更新内核后会自动编译适应的驱动模块 启用IOMMU一般系统编辑/etc/default/grub，找到GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet&quot;，在其后添加： Intel1intel_iommu=on iommu=pt AMD1amd_iommu=on iommu=pt 结果应该如下（Intel）： 1GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet intel_iommu=on iommu=pt&quot; ZFS上的系统编辑/etc/kernel/cmdline，找到root=ZFS=rpool/ROOT/pve-1 boot=zfs，在其后添加： Intel1intel_iommu=on iommu=pt AMD1amd_iommu=on iommu=pt 结果应该如下（Intel）： 1root=ZFS=rpool/ROOT/pve-1 boot=zfs intel_iommu=on iommu=pt 现在更新引导配置： 1proxmox-boot-tool refresh 禁止nouveau驱动nouveau是一个开源的NVIDIA显卡驱动，它与vGPU驱动冲突，必须禁用它 12echo &quot;blacklist nouveau&quot; &gt;&gt; /etc/modprobe.d/blacklist-nouveau.confecho &quot;options nouveau modeset=0&quot; &gt;&gt; /etc/modprobe.d/blacklist-nouveau.conf 加载vfio模块编辑&#x2F;etc&#x2F;modules，添加如下内容： 1234vfiovfio_iommu_type1vfio_pcivfio_virqfd 更新initramfs 1update-initramfs -u -k all 重启 1reboot 检查IOMMU是否启用重启后输入： 1dmesg | grep -e DMAR -e IOMMU 在我的C602双路服务器上，它输出以下内容： 12345678910111213141516171819202122232425root@pve-r720:~# dmesg | grep -e DMAR -e IOMMU[ 0.000000] Warning: PCIe ACS overrides enabled; This may allow non-IOMMU protected peer-to-peer DMA[ 0.012034] ACPI: DMAR 0x000000007D3346F4 000158 (v01 DELL PE_SC3 00000001 DELL 00000001)[ 0.012084] ACPI: Reserving DMAR table memory at [mem 0x7d3346f4-0x7d33484b][ 0.591102] DMAR: IOMMU enabled[ 1.347160] DMAR: Host address width 46[ 1.347161] DMAR: DRHD base: 0x000000d1100000 flags: 0x0[ 1.347168] DMAR: dmar0: reg_base_addr d1100000 ver 1:0 cap d2078c106f0466 ecap f020de[ 1.347170] DMAR: DRHD base: 0x000000dd900000 flags: 0x1[ 1.347175] DMAR: dmar1: reg_base_addr dd900000 ver 1:0 cap d2078c106f0466 ecap f020de[ 1.347177] DMAR: RMRR base: 0x0000007f458000 end: 0x0000007f46ffff[ 1.347178] DMAR: RMRR base: 0x0000007f450000 end: 0x0000007f450fff[ 1.347180] DMAR: RMRR base: 0x0000007f452000 end: 0x0000007f452fff[ 1.347181] DMAR: ATSR flags: 0x0[ 1.347183] DMAR-IR: IOAPIC id 2 under DRHD base 0xd1100000 IOMMU 0[ 1.347185] DMAR-IR: IOAPIC id 0 under DRHD base 0xdd900000 IOMMU 1[ 1.347186] DMAR-IR: IOAPIC id 1 under DRHD base 0xdd900000 IOMMU 1[ 1.347187] DMAR-IR: HPET id 0 under DRHD base 0xdd900000[ 1.347188] DMAR-IR: x2apic is disabled because BIOS sets x2apic opt out bit.[ 1.347189] DMAR-IR: Use &#x27;intremap=no_x2apic_optout&#x27; to override the BIOS setting.[ 1.347933] DMAR-IR: Enabled IRQ remapping in xapic mode[ 2.304979] DMAR: No SATC found[ 2.304981] DMAR: dmar0: Using Queued invalidation[ 2.304990] DMAR: dmar1: Using Queued invalidation[ 2.310738] DMAR: Intel(R) Virtualization Technology for Directed I/O 关键在于DMAR: IOMMU enabled一行，此行表明IOMMU已启用。 安装vGPU驱动注意本节使用535.54.06版驱动，GRID版本为16.0。 Proxmox VE作为KVM平台，自然需要KVM版的vGPU驱动 目前仅有16.0版的vGPU驱动支持新的6.2内核，15.3、15.1等版本最高支持到PVE 7 很不幸，NVIDIA不会让你随便下载高贵的GRID驱动（fuck-you-nvidia.jpg），你需要在这里注册一个免费的vGPU许可来下载驱动。 注意申请免费许可时，请勿使用@gmail.com、@qq.com等免费邮箱，否则可能会面临人工审核，我的建议是使用自己域名的邮箱。 提示觉得注册太麻烦？你也可以去佛西大佬的博客下载 下载完成后，解压zip文件，在Host_Drivers文件夹中找到NVIDIA-Linux-x86_64-535.54.06-vgpu-kvm.run，将其上传到Proxmox VE中 在Proxmox VE中执行以下命令： 1./NVIDIA-Linux-x86_64-535.54.06-vgpu-kvm.run --dkms 安装完成后，提示是否要注册DKMS模块，一定要选择Yes，这样在升级内核后，系统会重新编译适应新内核的驱动。 注意由于Proxmox VE使用apt update升级系统时不会升级pve-headers，因此务必在升级系统前安装新的pve-headers，避免造成dkms编译失败。 截屏2023-07-17 20.46.33 重启后执行nvidia-smi，在我的双Tesla P40机器上，输出以下内容（无视那些“vgpu”进程）： 截屏2023-07-17 20.58.06 执行mdevctl types查看mdev类型： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203root@pve-r720:~# mdevctl types0000:04:00.0 nvidia-156 Available instances: 0 Device API: vfio-pci Name: GRID P40-2B Description: num_heads=4, frl_config=45, framebuffer=2048M, max_resolution=5120x2880, max_instance=12 nvidia-215 Available instances: 0 Device API: vfio-pci Name: GRID P40-2B4 Description: num_heads=4, frl_config=45, framebuffer=2048M, max_resolution=5120x2880, max_instance=12 nvidia-241 Available instances: 0 Device API: vfio-pci Name: GRID P40-1B4 Description: num_heads=4, frl_config=45, framebuffer=1024M, max_resolution=5120x2880, max_instance=24 nvidia-46 Available instances: 0 Device API: vfio-pci Name: GRID P40-1Q Description: num_heads=4, frl_config=60, framebuffer=1024M, max_resolution=5120x2880, max_instance=24 nvidia-47 Available instances: 0 Device API: vfio-pci Name: GRID P40-2Q Description: num_heads=4, frl_config=60, framebuffer=2048M, max_resolution=7680x4320, max_instance=12 nvidia-48 Available instances: 0 Device API: vfio-pci Name: GRID P40-3Q Description: num_heads=4, frl_config=60, framebuffer=3072M, max_resolution=7680x4320, max_instance=8 nvidia-49 Available instances: 0 Device API: vfio-pci Name: GRID P40-4Q Description: num_heads=4, frl_config=60, framebuffer=4096M, max_resolution=7680x4320, max_instance=6 nvidia-50 Available instances: 0 Device API: vfio-pci Name: GRID P40-6Q Description: num_heads=4, frl_config=60, framebuffer=6144M, max_resolution=7680x4320, max_instance=4 nvidia-51 Available instances: 0 Device API: vfio-pci Name: GRID P40-8Q Description: num_heads=4, frl_config=60, framebuffer=8192M, max_resolution=7680x4320, max_instance=3 nvidia-52 Available instances: 0 Device API: vfio-pci Name: GRID P40-12Q Description: num_heads=4, frl_config=60, framebuffer=12288M, max_resolution=7680x4320, max_instance=2 nvidia-53 Available instances: 0 Device API: vfio-pci Name: GRID P40-24Q Description: num_heads=4, frl_config=60, framebuffer=24576M, max_resolution=7680x4320, max_instance=1 nvidia-54 Available instances: 0 Device API: vfio-pci Name: GRID P40-1A Description: num_heads=1, frl_config=60, framebuffer=1024M, max_resolution=1280x1024, max_instance=24 nvidia-55 Available instances: 0 Device API: vfio-pci Name: GRID P40-2A Description: num_heads=1, frl_config=60, framebuffer=2048M, max_resolution=1280x1024, max_instance=12 nvidia-56 Available instances: 0 Device API: vfio-pci Name: GRID P40-3A Description: num_heads=1, frl_config=60, framebuffer=3072M, max_resolution=1280x1024, max_instance=8 nvidia-57 Available instances: 0 Device API: vfio-pci Name: GRID P40-4A Description: num_heads=1, frl_config=60, framebuffer=4096M, max_resolution=1280x1024, max_instance=6 nvidia-58 Available instances: 0 Device API: vfio-pci Name: GRID P40-6A Description: num_heads=1, frl_config=60, framebuffer=6144M, max_resolution=1280x1024, max_instance=4 nvidia-59 Available instances: 0 Device API: vfio-pci Name: GRID P40-8A Description: num_heads=1, frl_config=60, framebuffer=8192M, max_resolution=1280x1024, max_instance=3 nvidia-60 Available instances: 0 Device API: vfio-pci Name: GRID P40-12A Description: num_heads=1, frl_config=60, framebuffer=12288M, max_resolution=1280x1024, max_instance=2 nvidia-61 Available instances: 0 Device API: vfio-pci Name: GRID P40-24A Description: num_heads=1, frl_config=60, framebuffer=24576M, max_resolution=1280x1024, max_instance=1 nvidia-62 Available instances: 0 Device API: vfio-pci Name: GRID P40-1B Description: num_heads=4, frl_config=45, framebuffer=1024M, max_resolution=5120x2880, max_instance=240000:42:00.0 nvidia-156 Available instances: 0 Device API: vfio-pci Name: GRID P40-2B Description: num_heads=4, frl_config=45, framebuffer=2048M, max_resolution=5120x2880, max_instance=12 nvidia-215 Available instances: 0 Device API: vfio-pci Name: GRID P40-2B4 Description: num_heads=4, frl_config=45, framebuffer=2048M, max_resolution=5120x2880, max_instance=12 nvidia-241 Available instances: 0 Device API: vfio-pci Name: GRID P40-1B4 Description: num_heads=4, frl_config=45, framebuffer=1024M, max_resolution=5120x2880, max_instance=24 nvidia-46 Available instances: 0 Device API: vfio-pci Name: GRID P40-1Q Description: num_heads=4, frl_config=60, framebuffer=1024M, max_resolution=5120x2880, max_instance=24 nvidia-47 Available instances: 0 Device API: vfio-pci Name: GRID P40-2Q Description: num_heads=4, frl_config=60, framebuffer=2048M, max_resolution=7680x4320, max_instance=12 nvidia-48 Available instances: 0 Device API: vfio-pci Name: GRID P40-3Q Description: num_heads=4, frl_config=60, framebuffer=3072M, max_resolution=7680x4320, max_instance=8 nvidia-49 Available instances: 0 Device API: vfio-pci Name: GRID P40-4Q Description: num_heads=4, frl_config=60, framebuffer=4096M, max_resolution=7680x4320, max_instance=6 nvidia-50 Available instances: 0 Device API: vfio-pci Name: GRID P40-6Q Description: num_heads=4, frl_config=60, framebuffer=6144M, max_resolution=7680x4320, max_instance=4 nvidia-51 Available instances: 0 Device API: vfio-pci Name: GRID P40-8Q Description: num_heads=4, frl_config=60, framebuffer=8192M, max_resolution=7680x4320, max_instance=3 nvidia-52 Available instances: 0 Device API: vfio-pci Name: GRID P40-12Q Description: num_heads=4, frl_config=60, framebuffer=12288M, max_resolution=7680x4320, max_instance=2 nvidia-53 Available instances: 0 Device API: vfio-pci Name: GRID P40-24Q Description: num_heads=4, frl_config=60, framebuffer=24576M, max_resolution=7680x4320, max_instance=1 nvidia-54 Available instances: 0 Device API: vfio-pci Name: GRID P40-1A Description: num_heads=1, frl_config=60, framebuffer=1024M, max_resolution=1280x1024, max_instance=24 nvidia-55 Available instances: 0 Device API: vfio-pci Name: GRID P40-2A Description: num_heads=1, frl_config=60, framebuffer=2048M, max_resolution=1280x1024, max_instance=12 nvidia-56 Available instances: 0 Device API: vfio-pci Name: GRID P40-3A Description: num_heads=1, frl_config=60, framebuffer=3072M, max_resolution=1280x1024, max_instance=8 nvidia-57 Available instances: 0 Device API: vfio-pci Name: GRID P40-4A Description: num_heads=1, frl_config=60, framebuffer=4096M, max_resolution=1280x1024, max_instance=6 nvidia-58 Available instances: 0 Device API: vfio-pci Name: GRID P40-6A Description: num_heads=1, frl_config=60, framebuffer=6144M, max_resolution=1280x1024, max_instance=4 nvidia-59 Available instances: 0 Device API: vfio-pci Name: GRID P40-8A Description: num_heads=1, frl_config=60, framebuffer=8192M, max_resolution=1280x1024, max_instance=3 nvidia-60 Available instances: 0 Device API: vfio-pci Name: GRID P40-12A Description: num_heads=1, frl_config=60, framebuffer=12288M, max_resolution=1280x1024, max_instance=2 nvidia-61 Available instances: 0 Device API: vfio-pci Name: GRID P40-24A Description: num_heads=1, frl_config=60, framebuffer=24576M, max_resolution=1280x1024, max_instance=1 nvidia-62 Available instances: 0 Device API: vfio-pci Name: GRID P40-1B Description: num_heads=4, frl_config=45, framebuffer=1024M, max_resolution=5120x2880, max_instance=24 配置vGPU授权服务器众所周知，vGPU的授权费极其昂贵，不是富哥很难承受的起，很长一段时间内，众多玩家采用伪造PCI ID的形式来伪装成Quadro显卡，从而骗过NVIDIA的检测。但目前已经有成熟的开源vGPU许可服务器fastapi-dls可以直接使用了，官方还提供了Docker，这省了许多事。 安装容器提示建议在虚拟机 &#x2F; LXC中部署此Docker镜像，PVE中直接安装Docker可能会导致VM断网等问题 12345678910111213# 拉取镜像docker pull collinwebdesigns/fastapi-dls:latest# 创建目录mkdir -p /opt/fastapi-dls/certcd /opt/fastapi-dls/cert# 生成公私钥openssl genrsa -out /opt/fastapi-dls/cert/instance.private.pem 2048 openssl rsa -in /opt/fastapi-dls/cert/instance.private.pem -outform PEM -pubout -out /opt/fastapi-dls/cert/instance.public.pem# 生成SSL证书openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout /opt/fastapi-dls/cert/webserver.key -out /opt/fastapi-dls/cert/webserver.crt# 创建容器, 1825是授权天数, YOUR_IP处填VM / LXC的IPdocker volume create dls-dbdocker run -d --restart=always -e LEASE_EXPIRE_DAYS=1825 -e DLS_URL=&lt;YOUR_IP&gt; -e DLS_PORT=443 -p 443:443 -v /opt/fastapi-dls/cert:/app/cert -v dls-db:/app/database collinwebdesigns/fastapi-dls:latest 自此，vGPU配置完成！ 参考资料NVIDIA Virtual GPU Software Documentation 佛西博客 - 在Proxmox VE 7.2 中开启vGPU_unlock，实现显卡虚拟化 (buduanwang.vip) PolloLoco &#x2F; NVIDIA vGPU Guide · GitLab oscar.krause&#x2F;fastapi-dls: Minimal Delegated License Service (DLS). This is a mirrored repo from https://git.collinwebdesigns.de/oscar.krause/fastapi-dls. - fastapi-dls - Gitea (publichub.eu) collinwebdesigns&#x2F;fastapi-dls - Docker Image | Docker Hub","tags":["云桌面","PVE","vGPU"]},{"title":"Intel 82599网卡不认光模块的解决方案","path":"/2023/06/24/solution-for-sfp-modules-not-supported-by-ixgbe/","content":"问题最近购买了一台RH1288H V3，想与R720之间构建万兆内网，于是弄了两个Huawei光模块，上机后发现R720找不到光模块所在网口，但是lspci可以看到网卡设备： 123root@pve-r720:~# lspci | grep 8259901:00.0 Ethernet controller: Intel Corporation 82599ES 10-Gigabit SFI/SFP+ Network Connection (rev 01)01:00.1 Ethernet controller: Intel Corporation 82599ES 10-Gigabit SFI/SFP+ Network Connection (rev 01) 执行dmesg ｜ grep ixgbe以后发现有不支持的模块报错 原因在于ixgbe驱动默认情况下仅支持Intel原厂光模块，使用第三方光模块会导致网卡驱动加载失败，插上模块时网络接口消失 解决方案临时1234# 卸载ixgbe驱动root@pve-r720:~# rmmod ixgbe# 以支持第三方模块模式重新加载ixgbe驱动root@pve-r720:~# modprobe ixgbe allow_unsupported_sfp=1 一劳永逸编辑grub配置文件/etc/default/grub，在GRUB_CMDLINE_LINUX项增加ixgbe.allow_unsupported_sfp=1： 截屏2023-06-24 22.21.18 更新grub： 1root@pve-r720:~# update-grub2 重启后生效 祝搞机愉快！","tags":["intel","82599","10Gb"]},{"title":"使用Wireguard实现异地组网并构建IPv6隧道","path":"/2023/06/02/wireguard-lan-fusion-with-ipv6-tunnel/","content":"前言最近在研究Wireguard异地组网，打算将家里和机房的局域网组合在一起。同时朋友有使用Wireguard IPv6上网的需求，决定再在组网的基础上添加一个IPv6隧道。 准备工作 两个网段不同的局域网（例如10.10.10.0/24 和 192.168.1.0/24） 两台OpenWrt（至少一个接入公网IPv6） 任意客户端 为机房PVE添加NAT网桥PVE默认的网桥是采用桥接方式，这次我要为它添加一个IPv4 &#x2F; IPv6双栈NAT网桥 添加网桥添加一个网桥vmbr1，如图所示，将10.10.10.1预留给OpenWrt，IPv6 ULA地址给OpenWrt自动分配 截屏2023-06-03 08.56.13 为了给vmbr1网桥下的设备分配IP地址，我们需要安装DHCP服务，这里由于组网需要我选择安装OpenWrt 安装OpenWrt创建虚拟机openwrt，配置如图所示 注意：先添加vmbr1再添加vmbr0，这样OpenWrt才会将vmbr0（互联网）视为WAN口 截屏2023-06-03 08.59.48 下载OpenWrt镜像并导入硬盘，这里可以参考我一篇没写完的文章（bushi https://rickg.cn/2022/05/25/pve-openwrt/https://rickg.cn/2022/05/25/pve-openwrt/ 推荐的镜像： https://openwrt.mpdn.fun:8443/https://openwrt.mpdn.fun:8443/ 1qm importdisk [vmid] /var/lib/vz/template/iso/bleach-plus-20230601-openwrt-x86-64-generic-squashfs-combined-efi.img local --format=qcow2 导入完成后，启动OpenWrt，编辑/etc/config/network，修改LAN口IP 截屏2023-06-03 09.10.01 重启OpenWrt后，在vmbr1网桥下任意虚拟机访问10.10.10.1，即可登录OpenWrt 配置NAT6安装完OpenWrt后，尽管此时我们拥有了IPv6 ULA地址，但未配置NAT6，因此并不能访问IPv6互联网 编辑/etc/sysctl.d/forward.conf ，添加以下内容： 1234net.ipv4.ip_forward=1net.ipv6.conf.all.forwarding=1net.ipv6.conf.eth1.autoconf=1net.ipv6.conf.eth1.accept_ra=2 其中eth1为WAN口接口名 重启OpenWrt后，访问10.10.10.1，打开网络-&gt;防火墙-&gt;自定义规则，添加以下内容： 12# Enable IPv6 NATip6tables -t nat -A POSTROUTING -o eth1 -j MASQUERADE 点击重启防火墙后，vmbr1下的IPv6设备应该可以访问IPv6互联网了 截屏2023-06-03 09.31.43 配置Wireguard VPN配置家中OpenWrtssh连接到路由器，创建密钥目录并设定掩码： 123mkdir keyscd keys umask 077 创建并查看密钥： 1234wg genkey &gt; openwrt-home.keycat openwrt-home.keywg pubkey &lt; openwrt-home.key &gt; openwrt-home.pubcat openwrt-home.pub 打开OpenWrt，点击网络-&gt;接口-&gt;添加新接口，名称为wg1，协议为WireGuard VPN 截屏2023-06-03 09.36.03 创建后自动打开接口编辑界面 截屏2023-06-03 13.15.01 将私钥填入配置界面，监听端口任意，建议选高位端口，防止被运营商干扰 IP地址一栏，我这里选用172.17.0.1/32的B类地址，个人建议用10.0.0.0/8的A类地址，自定义程度更高。对于IPv6地址，使用fd00::&#x2F;8开头的本地地址即可，如图中的fd45:da8::1&#x2F;64，配置完后保存并应用。 配置机房OpenWrt生成公私钥等同上，但是IP填172.17.0.2/32和fd45:da8::2/64，如图所示： 截屏2023-06-03 13.26.01 配置对端（Peer）登入任意路由器，生成一个预共享密钥，增强安全性： 1wg genpsk 该密钥在所有端通用，须保存好。 在Peers处点击添加，公钥填写对方的（如家里OpenWrt填写机房公钥），预共享密钥输入刚刚生成的，端点主机输入对端IP（这里我两端均为家宽，因此做了DDNS），端口输入配置的端口，持续Keep-Alive不填。 对于允许的IP，需要输入两项，第一项是WireGuard的IP段，即172.17.0.0/24，第二项即对方机器所处内网IP段，如对端为家则为192.168.1.0/24，如图所示： 截屏2023-06-03 13.36.24 配置完后保存并应用，点击WireGuard接口旁的“连接”，重启接口。 若要查看是否成功连接，点击LuCI界面中的状态-&gt;WireGuard状态即可看到对端连接信息： 截屏2023-06-03 13.39.43 此时ping一下对端内网段的IP，哈哈，是不是很激动？ 截屏2023-06-03 13.40.38 配置客户端创建密钥对于macOS &#x2F; Windows &#x2F; Android &#x2F; iOS等具有GUI等客户端，直接生成一对公私钥即可：截屏2023-06-03 17.09.05 image-20230603170949355 对于Linux，参照上文 编写配置文件添加空隧道，填写以下配置文件： 12345678910111213[Interface]PrivateKey = [你的私钥]Address = 172.17.0.4/32, fd45:da8::4/128DNS = 119.29.29.29, 2402:4e00::MTU = 1420[Peer]PublicKey = [服务端公钥]PresharedKey = [预共享密钥]AllowedIPs = 0.0.0.0/0, ::/0Endpoint = [服务端IP]:端口PersistentKeepalive = 25 对于允许的IP即AllowedIPs：填写0.0.0.0/0, ::/0即代理IPv4和IPv6所有流量，其他的一些示例： 123456# 只需访问内网段10.10.10.0/24，其他流量不走WireGuardAllowedIPs = 10.10.10.0/24# 全局代理，只允许IPv4流量AllowedIPs = 0.0.0.0/0# 全局代理，只允许IPv6流量AllowedIPs = ::/0 保存配置文件后，在WireGuard客户端中导入即可，当然，在正式使用之前，我们还需在服务端中添加客户端作为对端。 配置服务端打开OpenWrt的wg0接口，添加一个Peers，但是这次无需输入端点主机和端口，因为客户端可能位于多层NAT之后： 截屏2023-06-03 17.32.29 保存后，重启wg0接口，现在即可打开客户端享受安全、快速的WireGuard VPN了！","tags":["Wireguard","异地组网","IPv6"]},{"title":"使用iptables来通过网线共享网络","path":"/2023/05/31/iptables-one-wire-one-net/","content":"前言最近在计划加一台服务器，与原本的R720组成40G内网，然而路由器的网口已经不够了，心想能否直接通过40G网线来将R720的互联网共享给新机器，于是便有了这篇文章。 准备工作 计算机两台（一台要有双网卡 网线一根 互联网接入点一个 由于上面的我统统没有（bushi，所以这次技术验证放在了PVE中进行。 创建网桥vmbr1，无需绑定物理接口，模拟两机通过网线相连 创建两台虚拟机，名字分别为test-network、test-nonetwork ，配置如下（串行接口可以忽略 在两台机器上安装Debian 11系统 配置计算机AWell，现在我们来配置计算机A，也就是共享网络的机器 配置IP地址编辑/etc/network/interfaces ，添加如下内容 12345678910auto ens18iface ens18 inet dhcpallow-hotplug ens19iface ens19 inet static address 172.16.0.1/24 gateway 172.16.0.1iface ens19 inet6 static address 2001:db8::1234/64 gateway 2001:db8::1234 ens18 即连接互联网的端口，ens19 即与计算机B相连的端口 从上面的内容可以得知，我们要将ens19端口的IPv4地址配置为172.16.0.1，子网掩码为255.255.255.0，默认网关为本机IP；IPv6地址为2001:db8::1234，子网掩码为64，默认网关同样为本机IP。 配置iptables接下来是重头戏，没有iptables，就算两机的IP正确，计算机B也无法访问互联网。 安装iptables： 1sudo apt install iptables 输入以下指令： 123456789# IPv4 NATsudo iptables -t nat -A POSTROUTING -o ens18 -j MASQUERADEsudo iptables -A FORWARD -i ens18 -o ens19 -m state --state RELATED,ESTABLISHED -j ACCEPTsudo iptables -A FORWARD -i ens19 -o ens18 -j ACCEPT# IPv6 NATsudo ip6tables -t nat -A POSTROUTING -o ens18 -j MASQUERADEsudo ip6tables -A FORWARD -i ens18 -o ens19 -m state --state RELATED,ESTABLISHED -j ACCEPTsudo ip6tables -A FORWARD -i ens19 -o ens18 -j ACCEPT 这配置了网络地址转换（NAT） 保存iptables安装iptables-persistent： 1sudo apt-get install iptables-persistent 安装过程中会提示是否保存iptables，选择Yes即可 日后若要保存刚输入的iptables，键入sudo netfilter-persistent save即可 启用IP转发现在让我们进行最后一步：打开IPv4和IPv6的转发 编辑/etc/sysctl.conf ， 找到以下两行： 12#net.ipv4.ip_forward=1#net.ipv6.conf.all.forwarding=1 分别将其取消注释，同时在文件尾部添加以下两行： 12net.ipv6.conf.ens18.autoconf=1net.ipv6.conf.ens18.accept_ra=2 其中ens18为互联网端口号，由于IPv6转发的启用会全局禁用SLAAC获取IPv6地址，这两行将重新启用在该端口上的SLAAC功能。 保存文件，重新启动计算机，计算机A的配置部分就完成了。 配置计算机B计算机B的配置非常简单，只需要配置IP和默认网关即可 编辑/etc/network/interfaces ，添加以下内容： 1234567auto ens18iface ens18 inet static address 172.16.0.2/24 gateway 172.16.0.2iface ens18 inet6 static address 2001:db8::5678/64 gateway 2001:db8::1234 保存后重启计算机，就可以查看实际效果了。 测试ifconfig截屏2023-05-31 15.33.21 IPv4 Ping截屏2023-05-31 15.32.05 IPv6 Ping截屏2023-05-31 15.31.25 Speedtest截屏2023-05-31 15.37.40 缺点很显然，这种基于NAT的上网方式的缺点在于没有独立的IP地址。由于上游计算机无法获得IPv6前缀，本机也无法获得公网IPv6地址，对于一些需要公网IP的服务（例如BT）不是很友好。同时，NAT会降低网络性能。","tags":["iptables","网络"]},{"title":"NAS从入门到Boom② —— 安装Jellyfin并配置硬解","path":"/2023/02/27/nas-from-entry-to-boom-2/","content":"前言安装完Portainer以后，则是安装媒体服务器，这里我选择了开源、免费的Jellyfin，而安装方式则采用简单方便的docker-compose。 如何在Portainer中使用docker-compose访问Portainer后台，点击local image-20230227101834770 点击左侧的Stacks image-20230227101907477 点击Add stack image-20230227101958786 如图所示 image-20230227102126435 最后点击底部的Deploy the stack即可部署容器 (NVIDIA专属) 配置nvidia-docker-toolkit对于NVIDIA GPU，我们需要安装一点小小的软件包才能使它在docker容器里工作 参照：Installation Guide — NVIDIA Cloud Native Technologies documentation 我们直接使用官方的指令： 12345distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \\ &amp;&amp; curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\ &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \\ sed &#x27;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#x27; | \\ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list 然后安装nvidia-container-toolkit： 12sudo apt-get updatesudo apt-get install -y nvidia-container-toolkit 配置docker-compose话不多说，直接上配置文件： 使用NVENC1234567891011121314151617181920212223242526272829version: &quot;3&quot;services: jellyfin: image: nyanmisaka/jellyfin:latest # 使用中国特供版镜像，兼容性更好 container_name: jellyfin environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai - JELLYFIN_PublishedServerUrl=192.168.1.3 # 这里是你Jellyfin的地址 - NVIDIA_DRIVER_CAPABILITIES=all # NVIDIA专属配置项 - NVIDIA_VISIBLE_DEVICES=all # NVIDIA专属配置项 volumes: # volumes按需配置 - /path_to_your_config:/config - /path_to_your_tvshows:/data/tvshows - /path_to_your_movies:/data/movies - /path_to_your_animes:/data/animes ports: - 8096:8096 # http访问端口 - 8920:8920 # https访问端口 - 7359:7359/udp - 1900:1900/udp network_mode: bridge deploy: # 使用NVIDIA GPU的这样设置 resources: reservations: devices: - capabilities: [gpu] restart: unless-stopped 使用Video Acceleration API (VAAPI)123456789101112131415161718192021222324version: &quot;3&quot;services: jellyfin: image: nyanmisaka/jellyfin:latest # 使用中国特供版镜像，兼容性更好 container_name: jellyfin environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai - JELLYFIN_PublishedServerUrl=192.168.1.3 # 这里是你Jellyfin的地址 volumes: # volumes按需配置 - /path_to_your_config:/config - /path_to_your_tvshows:/data/tvshows - /path_to_your_movies:/data/movies - /path_to_your_animes:/data/animes ports: - 8096:8096 # http访问端口 - 8920:8920 # https访问端口 - 7359:7359/udp - 1900:1900/udp network_mode: bridge devices: - /dev/dri:/dev/dri restart: unless-stopped 配置完成后，如果你的显卡没有问题，docker容器应该很快会部署完成 没有Portainer？没有Portainer？不喜欢docker-compose？没关系，本部分将使用传统docker-cli部署Jellyfin 相关条目注释请看上一段 使用NVENC123456789101112131415161718docker run -d \\ --name=jellyfin \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Asia/Shanghai \\ -e JELLYFIN_PublishedServerUrl=192.168.0.5 \\ -e NVIDIA_DRIVER_CAPABILITIES=all \\ -e NVIDIA_VISIBLE_DEVICES=all \\ --gpus all \\ -p 8096:8096 \\ -p 8920:8920 \\ -p 7359:7359/udp \\ -p 1900:1900/udp \\ -v /path/to/library:/config \\ -v /path/to/tvseries:/data/tvshows \\ -v /path/to/movies:/data/movies \\ --restart unless-stopped \\ nyanmisaka/jellyfin:latest 使用Video Acceleration API (VAAPI)12345678910111213141516docker run -d \\ --device=/dev/dri:/dev/dri \\ --name=jellyfin \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Asia/Shanghai \\ -e JELLYFIN_PublishedServerUrl=192.168.0.5 \\ -p 8096:8096 \\ -p 8920:8920 \\ -p 7359:7359/udp \\ -p 1900:1900/udp \\ -v /path/to/library:/config \\ -v /path/to/tvseries:/data/tvshows \\ -v /path/to/movies:/data/movies \\ --restart unless-stopped \\ nyanmisaka/jellyfin:latest 配置Jellyfin登录Jellyfin，语言、地区选中文（这里我已经配置过所以不能再演示了），然后点击左上角的“三条杠”，再点击控制台，如图所示 image-20230227100358116 然后点击播放，如图所示 image-20230227100529209 如果你是NVIDIA GPU，按如图所示配置就可以了 image-20230227100622041 注：这里硬件解码格式建议和你GPU支持解码的格式相同，N卡可以参考此链接：https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new 如果你是Intel核显或者是想使用VAAPI，则按以下配置 image-20230227100853142 效果配置完成后保存，我们打开一个4K HDR视频看看效果 image-20230227101511721 可以看到视频可以较为流畅的播放（如果使用T400或者更好的显卡，转码帧率会更高）","tags":["nas","jellyfin"]},{"title":"使用Cloudflare Zero Trust进行内网穿透","path":"/2023/02/25/tutorial-cloudflare-zero-trust/","content":"介绍Zero Trust是Cloudflare公司推出的一项企业级虚拟网关服务，官方对其介绍如下： Cloudflare Zero TrustCloudflare Zero Trust是一个安全框架，旨在通过验证和保护所有的网络访问（无论用户或地点）来保护组织免受网络威胁。该框架基于 “不信任任何人 “的原则，这意味着所有访问请求在被批准之前必须经过验证和授权。 Zero Trust “旨在提供一种全面的安全方法，涵盖一个组织的网络和基础设施的所有方面。这包括用户认证、设备安全、网络分段和应用安全。 Zero Trust的主要好处之一是它能够提供细化的访问控制，使企业能够根据用户角色和权限限制对敏感资源的访问。这可以通过最小化攻击面和限制任何潜在漏洞的影响来帮助防止数据泄露和其他安全事件。 Cloudflare Zero Trust是一项基于云的服务，可以很容易地与组织的现有安全基础设施集成。它的设计具有可扩展性和灵活性，允许企业定制框架，以满足其特定需求和要求。 （通过DeepL翻译） 本文我们将使用其中的Tunnel功能，从外网访问家中内网的服务。对于其WARP代理功能，本文不做讨论。 你需要一个功能正常的Cloudflare账户 一个有效的付款方式（Visa / Mastercard /Paypal） 一个绑定在Cloudflare下的域名 启用Zero Trust 访问https://one.dash.cloudflare.com 选择Free计划 绑定付款方式并填写账单信息 一切正常的话，你将会看到Zero Trust的控制面板 image-20230225191137594 配置内网穿透创建隧道点击Access -&gt; Tunnels，点击Create a tunnel创建一个隧道 image-20230225191410406 输入名称后继续，提示安装connector image-20230225193025132 这里以Debian 64-bit和Windows为例 安装connector（Debian）键入以下命令： 1curl -L --output cloudflared.deb https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb &amp;&amp; sudo dpkg -i cloudflared.deb 若访问github.com过慢可在https://前面添加https://ghproxy.com/ 而后： 1sudo cloudflared service install [你的Token] 若运行此命令时出错 image-20230225192231356 则执行： 1sudo cloudflared service uninstall 而后重新执行cloudflared service install一行即可 安装connector（Windows）下载https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-windows-amd64.msi并安装 在以管理员权限运行的cmd &#x2F; Powershell中键入： 1cloudflare service install [你的Token] 进行内网穿透按照如图所示进行配置即可 image-20230225193655754 配置完成后，通过https://[你的子域名].[你的域名]/[你的访问路径(如果有的话)]即可访问内网服务 附：关于对内网HTTPS服务的特殊配置由于内网https服务证书一般为未受信任证书，若直接绑定到域名，访问时会提示Bad Gateway，因此需要对穿透的HTTPS做一些配置 打开Tunnels，点击隧道旁的Configure进入配置界面，选择Public Hostname image-20230225194302124 选择你要修改的域名，点击Edit image-20230225194404224 选择Additional application settings -&gt; TLS，将No TLS Verify一项启用 image-20230225194534026 保存后即可正常访问","tags":["内网穿透","Cloudflare"]},{"title":"NAS从入门到Boom① —— 基础环境的配置","path":"/2023/02/14/nas-from-entry-to-boom-1/","content":"前言最近在玩PT，大量的下载使得我硬盘不堪重负，于是改造家里的AIO服务器便提上了日程。因在刷PT时有观看影片转码的需求，遂选购HC320 8T一块，Quadro P400 2G一张。总体配置如下： Type Name CPU Xeon X3440 @ 2.53 GHz 主板 Supermicro X8SIL-V 内存 Kingston ECC UDIMM 2Rx8 8GB 显卡 NVIDIA Quadro P400 2GB SSD Kingston UV400 HDD Western Digital HC320 8TB 为何选择P400? 参照：https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new 根据nv最新的表格显示，P400拥有3路NVENC编码（甚至可以破解），支持H.264，H.265 10-bit等格式，同时对编码也有较好的支持，重点是拆机P400只要￥350，在一众解码卡中显得非常实惠。 系统安装 由于系统已经安装好了，这里以虚拟机作为演示 在https://proxmox.com/en/downloads下载安装镜像，用Rufus &#x2F; etcher刻入U盘 从安装镜像启动，同意用户协议，选择安装磁盘 image-20230214201346369 选择正确的时区 image-20230214201448024 配置密码 image-20230214201520389 配置IP地址 image-20230214201612459 安装完成后重启，浏览器访问https://[你配置的IP]:8006进入PVE管理界面 删除local-lvm并合并PVE在默认情况下会将系统盘分为local和local-lvm两个分区，在实际使用的时候往往其中一个不够用了另一个还很空的情况，一般来说在安装完成后将local-lvm合并入local，方便自己管理 以root登录后台，点击左边的节点，选择Shell，键入 1lvremove pve/data 输入y确认 image-20230214202932879 键入 1lvextend -l +100%FREE -r pve/root image-20230214202946857 在数据中心 - 存储中删除local-lvm，并编辑local，在内容一项中勾选所有可选项。 image-20230214203203190 image-20230214203243004 配置HDD点击左侧的节点，选择磁盘 image-20230214203357076 选择/dev/sdb，点击使用GPT初始化磁盘 使用zfs点击ZFS - 创建：ZFS，输入名称，选择设备，创建完成 image-20230214203913553 不使用zfs点击目录 - 创建：目录，输入名称，选择文件系统，创建完成 image-20230214204017067 配置软件源替换apt软件源替换前建议先更新下证书，否则可能由于证书不可用导致 https 无法使用，进而无法下载所有软件 1apt install apt-transport-https ca-certificates 编辑/etc/apt/sources.list 将原有内容替换为： 123456789101112deb https://mirrors.ustc.edu.cn/debian/ bullseye main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian/ bullseye main contrib non-freedeb https://mirrors.ustc.edu.cn/debian/ bullseye-updates main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian/ bullseye-updates main contrib non-freedeb https://mirrors.ustc.edu.cn/debian/ bullseye-backports main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian/ bullseye-backports main contrib non-freedeb https://mirrors.ustc.edu.cn/debian-security bullseye-security main contrib non-freedeb-src https://mirrors.ustc.edu.cn/debian-security bullseye-security main contrib non-free 禁用PVE企业源编辑/etc/apt/sources.list.d/pve-enterprise.list，将其中内容替换为如下以禁用企业源： 1deb https://mirrors.ustc.edu.cn/proxmox/debian bullseye pve-no-subscription 修改LXC容器源编辑/usr/share/perl5/PVE/APLInfo.pm，将第200行中http://download.proxmox.com/images替换为https://mirrors.ustc.edu.cn/proxmox/images即可，重启pvedaemon服务后生效： 1systemctl restart pvedaemon.service 配置显卡前置工作查看机器上识别到的NVIDIA GPU 1lspci | grep -i nvidia image-20230214211305042 安装内核头文件 12345# 查看内核版本号root@pve-sample:~# uname -r5.15.74-1-pve# 安装对应版本的头文件root@pve-sample:~# apt install pve-headers-5.15.74-1-pve 安装编译环境 1apt install gcc make 禁用开源驱动Linux默认会自带一个nv开源驱动（nouveau），此驱动与官方驱动冲突，必须将其禁用。 查看是否在使用nouveau： 1lsmod | grep nouveau 如有使用，创建配置文件禁用： 1nano /etc/modprobe.d/blacklist-nouveau.conf 写入以下内容后保存退出： 12blacklist nouveauoptions nouveau modeset=0 更新内核initramfs文件： 1update-initramfs -u 重启后生效。可以输入lsmod | grep nouveau验证 安装官方驱动 下载地址：https://www.nvidia.cn/Download/index.aspx?lang=cn 前往nvidia官网下载驱动 image-20230214212406811 下载并安装： 123wget https://cn.download.nvidia.com/XFree86/Linux-x86_64/525.89.02/NVIDIA-Linux-x86_64-525.89.02.runchmod +x NVIDIA-Linux-x86_64-525.89.02.run./NVIDIA-Linux-x86_64-525.89.02.run 一路回车即可 安装完毕后，重启服务器，输入nvidia-smi查看信息： image-20230214212708263 破解编码线程数限制在上面的表格中我们可以知道，万恶的黄🐶（f**k u nvidia）将所有消费级显卡和低端专业卡的编码线程数限制在3个线程（4090也不能同时开4个编码任务）。所幸有大神开发出了破解工具，可以一键解除黄🐶的限制。 项目主页：https://github.com/keylase/nvidia-patch 123wget https://ghproxy.com/https://raw.githubusercontent.com/keylase/nvidia-patch/master/patch.shchmod +x patch.sh./patch.sh 破解完成后，运行nvidia-smi检查GPU和驱动是否有错误。此外，可以通过ffmpeg来测试是否可以无限制编码： 123456ffmpeg -y -vsync 0 -hwaccel cuda -hwaccel_output_format cuda \\-f lavfi -i testsrc -t 50 \\-vf hwupload -c:a copy -c:v h264_nvenc -b:v 4M -f null - \\-vf hwupload -c:a copy -c:v h264_nvenc -b:v 1M -f null - \\-vf hwupload -c:a copy -c:v h264_nvenc -b:v 8M -f null - \\-vf hwupload -c:a copy -c:v h264_nvenc -b:v 6M -f null - image-20230214214429533 打开驱动持久模式 参考：https://www.reddit.com/r/PleX/comments/q0cbh9/quadro_p400_transcoding_information/ 这将使GPU驱动长时间加载，对于我的P400，实测可以在播放4K HDR视频时更流畅（不如说原来播放时就一卡一卡的）： 1nvidia-smi -pm 1 image-20230214214221730 安装软件zsh安装zshzsh作为一个极其好用的shell，是必须安装的（ 12345678# 安装 Zshapt install zsh# 将 Zsh 设置为默认 Shellchsh -s /bin/zsh# 安装 Oh My Zshwget https://ghproxy.com/https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 配置zsh必备插件zsh-autosuggestions历史命令建议插件 1git clone https://ghproxy.com/https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions zsh-syntax-highlighting语法高亮插件 1git clone https://ghproxy.com/https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting 配置~&#x2F;.zshrc将plugins=(git)修改为： 123456plugins=( git extract zsh-autosuggestions zsh-syntax-highlighting) 完成后切换到zsh，zsh应该是这个样子的： image-20230214215532887 Docker安装Docker使用官方一键脚本： 1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 配置Docker切换到国内源编辑/etc/docker/daemon.json（若不存在请新建）： 123&#123; &quot;registry-mirrors&quot;:[&quot;https://docker.mirrors.ustc.edu.cn/&quot;]&#125; 然后： 12systemctl daemon-reloadsystemctl restart docker 为docker容器启用IPv6因个人原因，需要Docker中的BT软件能访问IPv6，而docker默认是不启用IPv6的，需要手动开启 编辑/etc/docker/daemon.json： 1234567&#123; &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn/&quot;], &quot;experimental&quot;: true, &quot;ip6tables&quot;: true, &quot;ipv6&quot;: true, &quot;fixed-cidr-v6&quot;: &quot;fd00::/80&quot;&#125; 重启Docker： 1systemctl restart docker 查看Docker容器的IPv6状态： 1docker network inspect bridge image-20230214221048210 安装PortainerPortainer是一个优秀的容器管理器，用它我们可以轻易的创建 &#x2F; 管理Docker容器 1234# 创建Portainer数据卷docker volume create portainer_data# 安装Portainerdocker run -d -p 8000:8000 -p 9443:9443 -p 9000:9000 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest 安装完成后，通过http://[服务器ip]:9000或https://[服务器ip]:9443访问Portainer管理界面","tags":["nas","pve","docker"]},{"title":"Arma 3 获取与分析导弹数据","path":"/2022/11/25/arma3-get-and-analyze-missile-data/","content":"前言最近在研究Arma 3的SQF脚本，心想要是能收集一些游戏基础数据就好了，于是就有了这个项目。 所需ModFileXT 3den Enhanced（打开任务场景时需要） 制作流程1. 创建任务文件打开任务编辑器，创建一个空场景。 在场景内放置步枪兵 (未武装) x 1，类名为 B_Soldier_unarmed_F 在场景内放置野营桌若干 (要测试几种导弹就放几个)，类名为 Land_CampingTable_F image-20221125152852400 打开任务所在文件夹，路径为：文档 -&gt; Arma 3 - Other Profiles -&gt; 你的 ID -&gt; missions -&gt; 任务名 创建Description.ext文件，输入： 12345678910class CfgFunctions&#123;\tclass rickg\t&#123; class Utilities &#123; class missileTrack &#123;&#125;; &#125;;\t&#125;;&#125;; 创建Functions文件夹，并在其中创建Utilities文件夹 在Utilities文件夹中创建fn_missileTrack.sqf文件 2. 编写相关脚本在任务编辑器中双击野营桌，打开属性编辑页面。 image-20221125153845020 在初始化一栏中填入以下脚本： 1234567891011private _position = getPos this; // 获取桌子当前位置_position set [2, (_position select 2) + 1.3]; // 使导弹悬浮在桌子上方private _missile; private _missileType = &quot;PylonMissile_1Rnd_Missile_AA_04_F&quot;; // 这里和下面的_missileType为CfgMagazines中的导弹类型，可在配置查看器中查看_missile = createVehicle [getText (configFile &gt;&gt; &quot;CfgMagazines&quot; &gt;&gt; _missileType &gt;&gt; &quot;ammo&quot;), _position, [], 0, &quot;CAN_COLLIDE&quot;]; [_missile, [225.103, 0, 0]] call BIS_fnc_setObjectRotation; // 这行的225.103按你摆放桌子的方向来_missile enableSimulation false; // 禁用模拟，使导弹静止this addAction [format [&quot;测试 %1&quot;, getText (configFile &gt;&gt; &quot;CfgMagazines&quot; &gt;&gt; _missileType &gt;&gt; &quot;displayName&quot;)], &#123; private _missileType = &quot;PylonMissile_1Rnd_Missile_AA_04_F&quot;; [_missileType] call rickg_fnc_missileTrack; &#125;]; // 添加测试导弹的选项，这里使用了读取CfgMagazines动态获取导弹名 打开任务路径下的Functions/Utilities文件夹 编辑fn_missileTrack.sqf： 1234567891011121314151617181920212223242526272829303132333435363738params [&quot;_type&quot;];[_type] spawn &#123;\tparams [&quot;_type&quot;]; // 获取参数\t_typePlayer = player;\t_positionMissile = [0, 0, 1000]; // 设置导弹，跟踪无人机初始坐标为[0, 0, 1000]\t_positionDrone = [0, 0, 1000];\t_missile = createVehicle [getText (configFile &gt;&gt; &quot;CfgMagazines&quot; &gt;&gt; _type &gt;&gt; &quot;ammo&quot;), _positionMissile]; // 创建导弹实体\t_launchTime = time;\t_UAV = createVehicle [&quot;B_UAV_01_F&quot;, _positionDrone, [], 0, &quot;CAN_COLLIDE&quot;]; // 创建无人机实体\t_UAV attachTo [_missile, [0, 0, 0]]; // 将无人机附属在导弹上\t_UAV engineOn false;\t_UAV setFuel 0;\t_UAV allowDamage false; // 禁用无人机损害\thideObject _UAV; // 隐藏无人机模型\tcreateVehicleCrew _UAV;\tgunner _UAV allowDamage false; // 禁用无人机损害\tselectPlayer gunner _UAV; // 将玩家视角移动到无人机上\t// FileXT 获取文件名\tprivate _fileName_Time = getText (configFile &gt;&gt; &quot;CfgMagazines&quot; &gt;&gt; _type &gt;&gt; &quot;displayName&quot;) + &quot;_Time.txt&quot;;\t[_fileName_Time] call filext_fnc_deleteFile; // 删除旧文件\t[_fileName_Time] call filext_fnc_open; // 打开文件\tprivate _fileName_Dist = getText (configFile &gt;&gt; &quot;CfgMagazines&quot; &gt;&gt; _type &gt;&gt; &quot;displayName&quot;) + &quot;_Dist.txt&quot;;\t[_fileName_Dist] call filext_fnc_deleteFile;\t[_fileName_Dist] call filext_fnc_open;\twhile &#123;alive _missile&#125; do\t&#123; hintSilent format [&quot;型号: %1 速度: %2 km/h 高度变化: %3 m 飞行距离: %4 m 飞行时间: %5 s&quot;, getText (configFile &gt;&gt; &quot;CfgMagazines&quot; &gt;&gt; _type &gt;&gt; &quot;displayName&quot;), speed _missile, (getPos _missile select 2) - 1000, _positionMissile distance getPos _missile, time - _launchTime]; // 输出速度、高度变化、飞行距离等相关信息 [_fileName_Time, str(time - _launchTime), str(speed _missile)] call filext_fnc_set; // 添加键值到待写入项 [_fileName_Dist, str(_positionMissile distance getPos _missile), str((getPos _missile select 2) - 1000)] call filext_fnc_set;\t&#125;;\t[_fileName_Time] call filext_fnc_write; // 写入到文件\t[_fileName_Dist] call filext_fnc_write;\t[_fileName_Time] call filext_fnc_close; // 关闭文件流\t[_fileName_Dist] call filext_fnc_close;\tselectPlayer _typePlayer; // 切换回玩家\tdeleteVehicle _UAV;&#125;; 3. 测试挂载FileXT Mod，运行任务，导弹测试结果应该如下图 image-20221125155345765 测试完成后，打开Arma3安装目录/!Workshop/@FileXT/storage文件夹，可以发现生成了导弹名_Time.txt和导弹名_Dist.txt两个文件 image-20221125155841329 4. 整理数据文件用Visual Studio Code打开数据文件，可以发现有大量特殊符号，这是FileXT模组的存储模式导致的（详见https://github.com/Vindicta-Team/FileXT/wiki） image-20221125160355097 打开侧边栏的搜索一项，点击搜索框中的第三个图标启用正则表达式，而后将f.*\\u0001\\u0000&#123;3&#125;替换为空白，去掉文件开头的特殊符号 再将(.)\\u0000(.)替换为$1,$2，替换掉两个数字之间的NUL 而后将剩下的\\u0000替换为空白，这样所有特殊符号就被消除了 image-20221125161100799 在两个文件中搜索&quot;1000&quot;,0的无效数据项，将其删除 在两个文件中搜索&quot;a&quot;,0的无效数据项，将其删除（a的值与导弹飞行的时间相似） 5. 分析数据文件并导出为图片新建一个文件夹，在其下创建processData.py，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130import pandas as pdimport osimport matplotlib.pyplot as pltimport redef dirProcess(fileList: list, missileType: str): fileListTime = [] fileListDist = [] for i in fileList: if (re.search(&#x27;.*_Time.txt&#x27;, i) != None): fileListTime.append(re.search(&#x27;.*_Time.txt&#x27;, i).group()) if (re.search(&#x27;.*_Dist.txt&#x27;, i) != None): fileListDist.append(re.search(&#x27;.*_Dist.txt&#x27;, i).group()) for i in fileListTime: dataFrame = pd.read_table( &#x27;./导弹飞行数据/&#x27; + missileType + &#x27;/&#x27; + i, sep=&#x27;,&#x27;, header=None) dataFrame = dataFrame.sort_values(by=0) x = [] y = [] for index, row in dataFrame.iterrows(): x.append(row[0]) y.append(row[1]) figTime = plt.figure() ax = figTime.add_axes([0.12, 0.12, 0.8, 0.8]) ax.grid(True) ax.plot(x, y) ax.set_xlabel(&quot;飞行时间 (s)&quot;) ax.set_ylabel(&quot;速度 (km/h)&quot;) ax.set_title(i.split(&#x27;_&#x27;)[0] + &quot;导弹数据&quot;) plt.savefig(&#x27;./导弹飞行数据/图片/&#x27; + missileType + &#x27;/&#x27; + i.split(&#x27;_&#x27;) [0] + &quot;导弹数据_时间-速度.png&quot;, dpi=288) plt.close() for i in fileListDist: dataFrame = pd.read_table( &#x27;./导弹飞行数据/&#x27; + missileType + &#x27;/&#x27; + i, sep=&#x27;,&#x27;, header=None) dataFrame = dataFrame.sort_values(by=0) x = [] y = [] for index, row in dataFrame.iterrows(): x.append(row[0]) y.append(row[1]) figDist = plt.figure() ax = figDist.add_axes([0.12, 0.12, 0.8, 0.8]) ax.grid(True) ax.plot(x, y) ax.set_xlabel(&quot;飞行距离 (m)&quot;) ax.set_ylabel(&quot;相对高度 (m)&quot;) ax.set_title(i.split(&#x27;_&#x27;)[0] + &quot;导弹数据&quot;) plt.savefig(&#x27;./导弹飞行数据/图片/&#x27; + missileType + &#x27;/&#x27; + i.split(&#x27;_&#x27;) [0] + &quot;导弹数据_距离-高度.png&quot;, dpi=288) plt.close()def dirProcessinAll(fileList: list, missileType: str): fileListTime = [] fileListDist = [] for i in fileList: if (re.search(&#x27;.*_Time.txt&#x27;, i) != None): fileListTime.append(re.search(&#x27;.*_Time.txt&#x27;, i).group()) if (re.search(&#x27;.*_Dist.txt&#x27;, i) != None): fileListDist.append(re.search(&#x27;.*_Dist.txt&#x27;, i).group()) figure, axes = plt.subplots(1, 2, figsize=(38.4, 10.8), dpi=200) labels_time = [] labels_dist = [] axes[0].set_xlabel(&quot;飞行时间 (s)&quot;) axes[0].set_ylabel(&quot;速度 (km/h)&quot;) axes[0].set_title(missileType + &quot; 时间 - 速度 表&quot;) axes[0].grid(True) axes[1].set_xlabel(&quot;飞行距离 (m)&quot;) axes[1].set_ylabel(&quot;相对高度 (m)&quot;) axes[1].set_title(missileType + &quot; 距离 - 高度 表&quot;) axes[1].grid(True) for i in fileListTime: dataFrame = pd.read_table( &#x27;./导弹飞行数据/&#x27; + missileType + &#x27;/&#x27; + i, sep=&#x27;,&#x27;, header=None) dataFrame = dataFrame.sort_values(by=0) x = [] y = [] for index, row in dataFrame.iterrows(): x.append(row[0]) y.append(row[1]) axes[0].plot(x, y) labels_time.append(i.split(&#x27;_&#x27;)[0]) axes[0].legend(tuple(labels_time), loc=&#x27;best&#x27;) for i in fileListDist: dataFrame = pd.read_table( &#x27;./导弹飞行数据/&#x27; + missileType + &#x27;/&#x27; + i, sep=&#x27;,&#x27;, header=None) dataFrame = dataFrame.sort_values(by=0) x = [] y = [] for index, row in dataFrame.iterrows(): x.append(row[0]) y.append(row[1]) axes[1].plot(x, y) labels_dist.append(i.split(&#x27;_&#x27;)[0]) axes[1].legend(tuple(labels_dist), loc=&#x27;best&#x27;) # plt.show() plt.savefig(&#x27;./导弹飞行数据/图片/&#x27; + missileType + &#x27;/&#x27; + &quot;各导弹数据对比.png&quot;) plt.close()print(&quot;Please enter what the version you want to process &quot;)print(&quot;1. Single&quot;)print(&quot;2. All in One&quot;)cin = input()if (cin == &#x27;1&#x27;): # Process Ground to Ground Missiles dirProcess(os.listdir(&#x27;./导弹飞行数据/地地导弹&#x27;), &#x27;地地导弹&#x27;) # Process Air to Ground Missiles dirProcess(os.listdir(&#x27;./导弹飞行数据/空地导弹&#x27;), &#x27;空地导弹&#x27;) # Process Surface to Air Missiles dirProcess(os.listdir(&#x27;./导弹飞行数据/地空导弹&#x27;), &#x27;地空导弹&#x27;) # Process AA SR Missiles dirProcess(os.listdir(&#x27;./导弹飞行数据/近距弹&#x27;), &#x27;近距弹&#x27;) # Process AA MR Missiles dirProcess(os.listdir(&#x27;./导弹飞行数据/中距弹&#x27;), &#x27;中距弹&#x27;)elif (cin == &#x27;2&#x27;): # Process Ground to Ground Missiles dirProcessinAll(os.listdir(&#x27;./导弹飞行数据/地地导弹&#x27;), &#x27;地地导弹&#x27;) # Process Air to Ground Missiles dirProcessinAll(os.listdir(&#x27;./导弹飞行数据/空地导弹&#x27;), &#x27;空地导弹&#x27;) # Process Surface to Air Missiles dirProcessinAll(os.listdir(&#x27;./导弹飞行数据/地空导弹&#x27;), &#x27;地空导弹&#x27;) # Process AA SR Missiles dirProcessinAll(os.listdir(&#x27;./导弹飞行数据/近距弹&#x27;), &#x27;近距弹&#x27;) # Process AA MR Missiles dirProcessinAll(os.listdir(&#x27;./导弹飞行数据/中距弹&#x27;), &#x27;中距弹&#x27;) 在其下创建目录，目录树如下： 123456789101112└─导弹飞行数据 ├─中距弹 ├─图片 │ ├─中距弹 │ ├─地地导弹 │ ├─地空导弹 │ ├─空地导弹 │ └─近距弹 ├─地地导弹 ├─地空导弹 ├─空地导弹 └─近距弹 将你分析得到的导弹数据按分类放入导弹飞行数据文件夹下的分类即可 运行Python文件，在图片目录下即可查看输出的数据 6. 关于测试场景测试场景与Python代码我会一同打包放到网盘 下载地址：https://wwb.lanzoue.com/iTmkn0gvll7c","tags":["arma3","sqf"]},{"title":"设置OpenWrt的防火墙，从外网访问内网服务","path":"/2022/08/10/openwrt-config-ipv6-firewall/","content":"前言在运营商提供IPv6后，家中每一个内网设备都会拥有IPv6地址。 但是发现内网的设备，虽然有公网IPv6地址，但是仅仅能ping通，无法从外网访问。 最后发现是OpenWrt的防火墙阻断了连接，于是决定通过设置OpenWrt防火墙来开放端口。 设置打开OpenWrt管理界面，点击网络 → 防火墙 → 通信规则 点击添加与编辑： image-20220810174525648 按图编辑： image-20220810174827165 保存后，外网设备可以正常访问了","tags":["openwrt"]},{"title":"为比特彗星开放IPv6端口","path":"/2022/08/07/bitcomet-ipv6-green-light/","content":"12ip6tables -A FORWARD -p tcp --dport [BitComet端口] -j ACCEPTip6tables -A FORWARD -p udp --dport [BitComet端口] -j ACCEPT","tags":["bitcomet"]},{"title":"E5SubBot的配置使用","path":"/2022/07/10/configure-e5sub-bot/","content":"前言在拥有Office E5订阅后，如何续期成了一个大问题。最近找到了一个GitHub项目：iyear&#x2F;E5SubBot，决定用它来续期E5。 Requirements 1 * VPS（要能访问Telegram） 1 * Office E5账号 1 * Telegram账号 申请Telegram机器人添加@BotFather机器人，输入/start 开始 image-20220710162212450 输入/newbot创建新机器人 image-20220710162320105 输入bot名字 image-20220710162345391 输入bot用户名，得到bot的Token image-20220710162516659 配置E5SubBot在 Releases 页面下载对应系统的二进制文件，上传至服务器 重命名config.yml.example为config.yml 编辑config.yml，将bot_token一项的值修改为刚刚获取的Token 前往 https://t.me/userinfobot 获取自己的tgid，并填入admin项中 启动E5SubBot1234screen -S e5subchmod +x E5SubBot./E5SubBot(Ctrl A+D) 绑定账号参照以下教程（图片来自网络） E5Sub_1 E5Sub_2 E5Sub_3 E5Sub_4 E5Sub_5 E5Sub_6","tags":["Office E5"]},{"title":"记一次给PVE配置ddns","path":"/2022/06/01/pve-configure-ddns/","content":"前言随着ipv6的普及，越来越多的终端支持ipv6。因此我决定给家中的Proxmox VE配置ipv6并配置ddns以通过外网访问。 Requirements 一台支持ipv6的路由器 Proxmox VE主机 一个域名 ddns-go 为Proxmox VE启用ipv6Proxmox安装后默认没有通过SLAAC配置公网ipv6地址，需要手动配置 在/etc/sysctl.conf中添加： 123456net.ipv6.conf.all.accept_ra=2net.ipv6.conf.default.accept_ra=2net.ipv6.conf.vmbr0.accept_ra=2net.ipv6.conf.all.autoconf=1net.ipv6.conf.default.autoconf=1net.ipv6.conf.vmbr0.autoconf=1 来为vmbr0网桥启用自动获取公网ipv6地址 重启后输入ifconfig： image-20220601090839399 ping外网也是正常的 image-20220601090957203 安装ddns-go前往项目的GitHub Release页面下载最新版本，这里以3.7.1版为例 解压到&#x2F;opt12mkdir -p /opt/ddns-gotar -zxvf ddns-go_3.7.1_Linux_x86_64.tar.gz -C /opt/ddns-go 设置为系统服务123cd /opt/ddns-go./ddns-go -s install# 卸载服务请执行 ./ddns-go -s uninstall 配置ddns-go访问http://[服务器ip]:9876 设置dns服务商 勾选IPv6项下的是否启用，并添加解析域名 现在可以通过指定的域名来访问pve服务了","tags":["pve","ddns"]},{"title":"为Cloudreve添加离线下载节点","path":"/2022/05/29/cloudreve-child-node/","content":"前言在配置Cloudreve期间，发现VPS仅有的60G空间对于离线下载远远不够，因此决定将内网的一台机器作为Cloudreve的离线下载节点。 思路在子节点上运行Cloudreve和Aria2，并通过frp将子节点服务暴露给公网，最后通过Cloudreve自带的功能进行子节点离线下载 Cloudreve 支持“从机离线下载”，您可以将离线下载任务分流至多台服务器处理，避免这些任务过多占用主机的资源。每个负责处理离线下载任务的节点需要运行一组 Cloudreve 和 Aria2 实例。您可以按照管理面板中的节点添加向导指引配置并添加新节点。 Requirements 1 * 拥有公网ip的机器 1 * 无公网ip的机器 frp软件 Cloudreve 准备步骤内网机安装Cloudreve参见安装配置Cloudreve 安装frp参见frp内网穿透教程 安装aria21234apt install aria2# 创建aria2配置文件mkdir -p /etc/aria2nano /etc/aria2/aria2.conf 在/etc/aria2/aria2.conf中添加 123456# 启用 RPC 服务enable-rpc=true# RPC 监听端口rpc-listen-port=6800# RPC 授权令牌，可自行设定rpc-secret=&lt;your token&gt; 创建aria2用户 1useradd aria2 编辑/etc/systemd/system/aria2c.service： 1234567891011[Unit]Description= Aria2c ServiceAfter=network.target[Service]Type=simpleUser=aria2ExecStart=/usr/bin/aria2c --conf-path=/etc/aria2/aria2.conf[Install]WantedBy=multi-user.target 创建离线下载临时文件夹，并设置权限防止报错 1234mkdir /offline_download# 将所有者改为aria2用户并设置权限chown -R aria2 /offline_downloadchmod -R 777 /offline_download 配置frp/etc/frp/frpc.ini 12345678910111213141516[common]server_addr = 公网机ipserver_port = 7000[https2http]type = httpscustom_domains = 访问内网服务用的域名plugin = https2httpplugin_local_addr = 127.0.0.1:5212# HTTPS 证书相关的配置plugin_crt_path = 域名证书crt文件路径plugin_key_path = 域名证书key文件路径plugin_host_header_rewrite = 127.0.0.1plugin_header_X-From-Where = frp 注：这里我公网机Cloudreve使用了https，则暴露内网机服务时必须也使用https 公网机安装frp、Cloudreve略配置frp在服务端frp配置中添加用于访问内网Cloudreve的HTTPS端口 /etc/frp/frps.ini： 123[common]bind_port = 7000vhost_https_port = 访问用端口 配置Cloudreve现在可以通过https://[公网机ip]:端口访问内网的Cloudreve了 打开公网机上的Cloudreve，点击管理面板→离线下载节点→接入新节点，打开添加新节点界面，复制生成的从机密钥 在内网机上Cloudreve配置文件中添加： 12[Slave]Secret = 从机密钥 并修改Mode字段的值为slave，重启Cloudreve 在管理面板从机地址中填入https://[公网机ip]:端口，并测试是否正常 点下一步→启用，在RPC授权令牌中填入aria2c.conf中的rpc-secret RPC服务地址填http://127.0.0.1:6800/ 绝对路径填离线下载文件夹在内网机上的位置，如/offline_download 完成后测试aria2通信，检查是否正常 点击下一步设置节点名字，自此，离线下载节点添加完成","tags":["cloudreve"]},{"title":"安装配置Cloudreve","path":"/2022/05/29/cloudreve/","content":"前言自从申请到Office E5之后便有了容量高达5TB的OneDrive。心想怎能没有一个配套的网盘程序呢，于是便有了此文。 何为Cloudreve？以下内容来自官方文档 Cloudreve 可以让您快速搭建起公私兼备的网盘系统。Cloudreve 在底层支持不同的云存储平台，用户在实际使用时无须关心物理存储方式。你可以使用 Cloudreve 搭建个人用网盘、文件分享系统，亦或是针对大小团体的公有云系统。 安装Cloudreve 本文以Debian 10 (buster)，amd64架构，Cloudreve 3.5.3为准，Cloudreve安装在&#x2F;opt&#x2F;cloudreve 下载前往Github Release页面根据系统架构下载最新版本 解压到&#x2F;opt1234mkdir -p /opt/cloudrevetar -zxvf cloudreve_3.5.3_linux_amd64.tar.gz -C /opt/cloudreve# 添加可执行权限chmod +x /opt/cloudreve/cloudreve 获取初始管理员密码12cd /opt/cloudreve./cloudreve 你应该看到如下图所示的界面 image-20220529184316860 配置systemd新建/usr/lib/systemd/system/cloudreve.service： 12345678910111213141516171819[Unit]Description=CloudreveDocumentation=https://docs.cloudreve.orgAfter=network.targetAfter=mysqld.serviceWants=network.target[Service]WorkingDirectory=/opt/cloudreveExecStart=/opt/cloudreve/cloudreveRestart=on-abnormalRestartSec=5sKillMode=mixedStandardOutput=nullStandardError=syslog[Install]WantedBy=multi-user.target 而后 12345678# 更新配置systemctl daemon-reload# 启动服务systemctl start cloudreve# 设置开机启动systemctl enable cloudreve 管理命令： 1234567891011# 启动服务systemctl start cloudreve# 停止服务systemctl stop cloudreve# 重启服务systemctl restart cloudreve# 查看状态systemctl status cloudreve 配置反代现在可以通过http://[server_ip]:5212来访问Cloudreve了，若有通过HTTPS访问的需求，则需配置反代（以nginx为例） 在网站的server字段中加入： 123456789location / &#123; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_redirect off; proxy_pass http://127.0.0.1:5212; # 如果您要使用本地存储策略，请将下一行注释符删除，并更改大小为理论最大文件尺寸 # client_max_body_size 20000m;&#125; 配置Cloudreve访问Cloudreve后台，使用初始用户密码登录 点击右上角的头像→管理面板，会询问是否修正站点URL，确认即可 image-20220529184746382 修改默认用户密码在管理面板中点击用户，在右边的用户列表中修改即可 添加存储策略管理面板→存储策略→添加存储策略，如下图所示 image-20220529185722835 各存储策略对比&nbsp;–&nbsp;Cloudrevehttps://docs.cloudreve.org/use/policy/compare 各存储策略的官方引导式配置已十分详细，这里不再赘述 杂项忘记了密码？1/opt/cloudreve/cloudreve --database-script ResetAdminPassword 校准用户容量1/opt/cloudreve/cloudreve --database-script CalibrateUserStorage","tags":["cloudreve"]},{"title":"frp内网穿透教程","path":"/2022/05/28/how-to-configure-frp/","content":"前言frp是什么frp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。 项目地址：https://github.com/fatedier/frp/ 为什么要写这篇文章最近在折腾arma3的服务器，饱受没有公网ip之困扰。为此写下这篇教程记录我折腾内网穿透的整个过程。 本文部分参考了官方文档的内容 全文以写作这篇文章的最新版（v0.43.0）为准 配置环境：Debian 10 64-bit 下载frp1wget https://github.com/fatedier/frp/releases/download/v0.43.0/frp_0.43.0_linux_amd64.tar.gz 安装frp解压1tar -zxvf frp_0.43.0_linux_amd64.tar.gz 复制到系统目录1234cd frp_0.43.0_linux_amd64/mkdir -p /etc/frpmv *.ini /etc/frpmv frpc frps /usr/bin 配置systemd公网机新建/usr/lib/systemd/system/frps.service: 1234567891011121314[Unit]Description=Frp Server ServiceAfter=network.target[Service]Type=simpleUser=nobodyRestart=on-failureRestartSec=5sExecStart=/usr/bin/frps -c /etc/frp/frps.iniLimitNOFILE=1048576[Install]WantedBy=multi-user.target 随后执行 1systemctl enable frps 内网机新建/usr/lib/systemd/system/frpc.service: 123456789101112131415[Unit]Description=Frp Client ServiceAfter=network.target[Service]Type=simpleUser=nobodyRestart=on-failureRestartSec=5sExecStart=/usr/bin/frpc -c /etc/frp/frpc.iniExecReload=/usr/bin/frpc reload -c /etc/frp/frpc.iniLimitNOFILE=1048576[Install]WantedBy=multi-user.target 随后执行 1systemctl enable frpc 启动frp公网机1systemctl start frps 内网机1systemctl start frpc 注：每次修改完配置应通过systemctl restart重启服务 配置frp普通服务（以SSH为例）公网机修改/etc/frp/frps.ini 12[common]bind_port = 7000 内网机修改/etc/frp/frpc.ini 123456789[common]server_addr = 公网机ipserver_port = 7000[ssh]type = tcplocal_ip = 127.0.0.1local_port = 本地SSH端口remote_port = 公网访问服务用的端口 其他服务以此类推，如我的Arma 3服务器配置为： 123456789101112131415[common]server_addr = xxx.xxx.xxx.xxxserver_port = 7000[arma3-1]type = udplocal_ip = 127.0.0.1local_port = 2302remote_port = 2302[arma3-2]type = udplocal_ip = 127.0.0.1local_port = 2303remote_port = 2303 Web服务（HTTP）在公网机frps.ini中添加一行 1vhost_http_port = 8080 即设置http请求端口为8080 在内网机frpc.ini中添加 1234[web]type = httplocal_port = 80custom_domains = your.domain 分别启动frps，frpc。并将your.domain的A记录解析至公网机 访问http://your.domain:8080来访问内网服务 Web服务（HTTPS）在公网机/etc/frp/frps.ini中添加 1vhost_https_port = 443 即设置https请求端口为443 暴露本地HTTP服务在内网机/etc/frp/frpc.ini中添加 123456789101112[test_htts2http]type = httpscustom_domains = your.domainplugin = https2httpplugin_local_addr = 127.0.0.1:80# HTTPS 证书相关的配置plugin_crt_path = ./server.crtplugin_key_path = ./server.keyplugin_host_header_rewrite = 127.0.0.1plugin_header_X-From-Where = frp 分别启动frpc，frps 访问https://your.domain来访问内网服务 暴露本地HTTPS服务在内网机/etc/frp/frpc.ini中添加 123456789[https2https]type = httpscustom_domains = your.domainplugin = https2httpsplugin_local_addr = 127.0.0.1:443# 证书和密钥位置plugin_crt_path = /etc/frp/server.crtplugin_key_path = /etc/frp/server.key 杂项服务端Web界面在公网机的/etc/frp/frps.ini的common中添加 1234dashboard_port = 7500# 用户名和密码dashboard_user = admindashboard_pwd = admin 通过http://[公网机ip]:7500来访问服务端Web界面 客户端Web界面在内网机的/etc/frp/frpc.ini的common中添加 1234admin_addr = 127.0.0.1admin_port = 7400admin_user = adminadmin_pwd = admin 通过http://127.0.0.1:7400来访问客户端Web界面","tags":["frp","教程"]},{"title":"在自有服务器上部署Snapdrop","path":"/2022/05/28/deploy-snapdrop/","content":"前言购入笔记本和备用机后，对于家里多设备互传文件需求增加了，恰好被@Copur安利这样一个项目，于是便打算在自己的服务器上部署 Bellisario/node-snapdrop:&nbsp;Node&nbsp;version&nbsp;of&nbsp;the&nbsp;original&nbsp;Snapdrophttps://github.com/Bellisario/node-snapdrop 服务器端配置clone项目 123git clone https://github.com/Bellisario/node-snapdrop.git# 速度慢可考虑fastgitgit clone https://hub.fastgit.xyz/Bellisario/node-snapdrop.git 安装依赖 12cd node-snapdropnpm install 安装pm2 1npm install -g pm2 启动Snapdrop 1pm2 start index.js 现在可以通过localhost:3000来访问Snapdrop了 反代配置在网站nginx配置文件头部加入 1234567map $http_upgrade $connection_upgrade &#123;default upgrade;&#x27;&#x27; close;&#125;upstream websocket &#123; server 127.0.0.1:3000;&#125; 在反代配置文件的location ^~ / 下加入 12proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection $connection_upgrade; CDN配置 （以又拍云为例）又拍云控制台创建WebSocket服务，域名填需要绑定的域名，协议http，端口80，如图所示 image-20220528152422766 随后在服务的https配置中添加证书，配置完成","tags":["Snapdrop"]},{"title":"powershell美化","path":"/2022/05/28/powershell-polish/","content":"效果图image-20220528135813783 安装oh-my-posh在Microsoft Store安装Windows Terminal 执行如下命令 123Set-ExecutionPolicy BypassInstall-Module oh-my-posh -Scope CurrentUserInstall-Module posh-git -Scope CurrentUser 如有提示按y即可 启用oh-my-posh配置PowerShell启动脚本 1notepad $PROFILE 导入相应模块 12Import-Module oh-my-poshImport-Module posh-git 设置主题为agnosterplus 1Set-PoshPrompt -Theme agnosterplus 解决字体乱码 参见 Oh My Posh Docs 下载Nerd Fonts，这里我选择的是Meslo Fonts 下载地址https://www.nerdfonts.com/font-downloads 解压，选择Meslo LG S Regular Nerd Font Complete Windows Compatible.ttf并安装 打开Windows Terminal，按Ctrl + , 打开设置，点击Windows Powershell –&gt; 外观，将字体改为刚才安装的MesloLGS NF，如图所示 image-20220528135059127 启用模糊背景设置 –&gt; Windows Powershell –&gt; 外观 –&gt; 透明度 启用 Enable acrylic 项 image-20220528135302118 允许PowerShell执行任意脚本1Set-ExecutionPolicy Unrestricted","tags":["powershell","美化"]},{"title":"基于pve的Openwrt安装及配置","path":"/2022/05/25/pve-openwrt/","content":"机器介绍 类别 型号 CPU Xeon X3440 @ 2.53GHz 主板 Supermicro X8SIL 内存 Kingston ECC 8GB DDR3-1600 硬盘 Kingston UV400 系统 Proxmox VE 7.2 Proxmox VE的安装与配置Step.1 制作启动盘在pve官网下载pve的镜像（我这里使用的是7.2版，下载速度可能很慢，方法…你们懂得）然后使用相关工具写入即可，推荐使用balenaEtcher。 写入启动盘 Step.2 安装pve将U盘插入电脑，开机选择U盘启动，进入引导界面，选择Install Proxmox VE进入pve安装程序 pve引导界面 点agree同意协议 pve-license 选择安装磁盘（这里开了个虚拟机来截图） pve-seldisk 设置root密码和邮箱 pve-password 按实际情况配置网络，一般情况下会自动获取ip等信息 pve-setnetwork 最后确认信息，点Install安装系统 pve-confirm Step.3 配置pve安装完后通过https://[你设置的ip，如图中的192.168.3.7]:8006访问pve管理界面 username填root，密码填安装系统时设置的密码 pve-login 进入管理界面会弹出无有效订阅的提示，这个我们稍后会消除 选择左边数据中心下的唯一一个节点，点击Shell进入终端，运行以下命令安装pvetools： 1echo &quot;nameserver 8.8.8.8&quot; &gt;&gt; /etc/resolv.conf &amp;&amp; rm /etc/apt/sources.list.d/pve-enterprise.list &amp;&amp; export LC_ALL=en_US.UTF-8 &amp;&amp; apt update &amp;&amp; apt -y install git &amp;&amp; git clone https://github.com/ivanhao/pvetools.git &amp;&amp; cd pvetools &amp;&amp; ./pvetools.sh 安装完成后会自动打开pvetools，语言选择中文 pve-pvetools 配置国内源并去除订阅提示，其他按需求选择（我的Openwrt需要一个直通网口，这里配置了直通） 完成后执行reboot重启，这时再打开管理界面，烦人的订阅提示已经消失了 OpenWrt的安装与配置Step.1 配置虚拟机点击管理界面右上角的创建虚拟机，名称随便 pve-createvm 选择不使用任何介质 pve-selsystem 机型，BIOS什么的保持默认。磁盘大小默认，待会要删除 CPU这里我选择1核 pve-cpu 内存按需求定，这里我填1024MB pve-memory 网络这里，模型选virtio（性能较高，除了OpenWrt里会提示半双工，实际上是全双工）。这里使用OpenWrt的防火墙，将防火墙一项取消选择 pve-network2 最后创建虚拟机，完成后在左边列表里选择虚拟机，点击右边的硬件，选中刚创建的虚拟磁盘，点击分离，选中分离出的硬盘，点击删除 pve-deldisk Step.2 安装OpenWrt选取适合自己的OpenWrt镜像，这里推荐一个 FW867&nbsp;大神&nbsp;KoolShare&nbsp;LEDE&nbsp;软路由固件https://www.koolcenter.com/posts/49 将镜像（img格式）上传到pve中 注：这里我合并了local和local-lvm，因此图中只显示local pve-uploadiso 在pve的shell中输入： 1qm importdisk 虚拟机id /var/lib/vz/template/iso/镜像名字.img local-lvm 导入成功后显示successful 回到虚拟机硬件界面，选中新添加的硬盘，点击编辑，选择设备类型为SATA，点击添加，完成 pve-add-disk 进入虚拟机选项页面，点击引导顺序，只选择新添加的SATA硬盘，点击OK保存 pve-boot-order 启动虚拟机，进入openwrt 若启动虚拟机时报错：failed to set iommu for container 请执行以下命令： 1echo &quot;options vfio_iommu_type1 allow_unsafe_interrupts=1&quot; &gt; /etc/modprobe.d/iommu_unsafe_interrupts.conf 而后重启即可解决问题 未完待续…","tags":["openwrt","pve","软路由"]},{"path":"/about/index.html","content":"AboutGamesDevices模拟飞行爱好者 &#x2F; 摄影爱好者 &#x2F; PC玩家，爱折腾一些新奇玩意NameSinceTimeArma 320181200h +Grand Theft Auto V2018200h +Cyberpunk 2077202080hEuro Truck Simulator 2202020h +DCS World202170h +TypeModel📱iPhone 13Redmi Note 8 Pro📷Canon EOS R6🎧Huawei Freebuds Studio"},{"title":"友链","path":"/friends/index.html","content":"乐得自在的小破站鑫大的博客EdgelessWNGAMEBOXHoratioRan's BlogDmcimi's Blog酸酸のBlogBlog233"},{"title":"便签","path":"/notes/index.html","content":""}]